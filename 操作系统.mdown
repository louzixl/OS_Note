摘自C语言中文网-操作系统
[TOC]

### 进程和线程管理
由程序段、相关数据段和PCB三部分构成了进程映像（进程实体）。所谓创建进程，实质上是创建进程映像中的PCB；而撤销进程，实质上是撤销进程的PCB。

PCB是进程存在的唯一标志！

进程是具有独立功能的程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位。

异步性：由于进程的相互制约，使进程具有执行的间断性，即进程按各自独立的、 不可预知的速度向前推进。异步性会导致执行结果的不可再现性，为此，在操作系统中必须配置相应的进程同步机制。

通常进程有以下五种状态，前三种是进程的基本状态。[如图](http://c.biancheng.net/cpp/uploads/allimg/140629/1-14062Z21T1A4.png)

  1. 运行状态：进程正在处理机上运行。在单处理机环境下，每一<font color = 'red'>时刻</font>最多只有一个进程处于运行状态。
  2. 就绪状态：进程已处于准备运行的状态，即进程获得了<font color = 'red'>除处理机之外</font>的一切所需资源，一旦得到处理机即可运行。
  3. 阻塞状态，又称等待状态：进程正在等待某一事件而暂停运行，如等待某资源为可用（不包括处理机）或等待输入/输出完成。即使处理机空闲，该进程也不能运行。
  4. 创建状态：进程正在被创建，尚未转到就绪状态。创建进程通常需要多个步骤：首先申请一个空白的PCB，并向PCB中填写一些控制和管理进程的信息；然后由系统为该进程分配运行时所必需的资源；最后把该进程转入到就绪状态。
  5. 结束状态：进程正从系统中消失，这可能是进程正常结束或其他原因中断退出运行。当进程需要结束运行时，系统首先必须置该进程为结束状态，然后再进一步处理资源释放和回收等工作。

#### 进程控制
在操作系统中，一般把进程控制用的程序段称为原语，原语的特点是执行期间不允许中断，它是一个不可分割的基本单位。

允许一个进程创建另一个进程。此时创建者称为父进程，被创建的进程称为子进程。子进程可以继承父进程所拥有的资源。当子进程被撤销时，应将其从父进程那里获得的资源归还给父进程。此外，在撤销父进程时，也必须同时撤销其所有的子进程。

在操作系统中，终端用户登录系统、作业调度、系统提供服务、用户程序的应用请求等都会引起进程的创建。操作系统创建一个新进程的过程如下（创建原语)：

  1. 为新进程分配一个唯一的进程标识号，并申请一个空白的PCB(PCB是有限的)。若PCB申请失败则创建失败。
  2. 为进程分配资源，为新进程的程序和数据、以及用户栈分配必要的内存空间（在PCB 中体现）。注意：这里如果资源不足（比如内存空间），并不是创建失败，而是处于”等待状态“，或称为“阻塞状态”，等待的是内存这个资源。
  3. 初始化PCB,主要包括初始化标志信息、初始化处理机状态信息和初始化处理机控制信息，以及设置进程的优先级等。
  4. 如果进程就绪队列能够接纳新进程，就将新进程插入到就绪队列，等待被调度运行。

引起进程终止的事件主要有：正常结束，表示进程的任务已经完成和准备退出运行。异常结束是指进程在运行时，发生了某种异常事件，使程序无法继续运行，如存储区越界、保护错、非法指令、特权指令错、I/O故障等。外界干预是指进程应外界的请求而终止运行，如操作员或操作系统干预、父进程请求和父进程终止。

操作系统终止进程的过程如下（撤销原语）：  

  1. 根据被终止进程的标识符，检索PCB，从中读出该进程的状态。
  2. 若被终止进程处于执行状态，立即终止该进程的执行，将处理机资源分配给其他进程。
  3. 若该进程还有子进程，则应将其所有子进程终止。
  4. 将该进程所拥有的全部资源，或归还给其父进程或归还给操作系统。
  5. 将该PCB从所在队列（链表）中删除。

正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。

阻塞原语的执行过程是：

  1. 找到将要被阻塞进程的标识号对应的PCB。
  2. 若该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行。
  3. 把该PCB插入到相应事件的等待队列中去。

当被阻塞进程所期待的事件出现时，如它所启动的I/O操作已完成或其所期待的数据已到达，则由有关进程（比如，提供数据的进程）调用唤醒原语(Wakeup)，将等待该事件的进程唤醒。

唤醒原语的执行过程是：

  1. 在该事件的等待队列中找到相应进程的PCB。
  2. 将其从等待队列中移出，并置其状态为就绪状态。
  3. 把该PCB插入就绪队列中，等待调度程序调度。

需要注意的是，Block原语和Wakeup原语是一对作用刚好相反的原语，必须成对使用。 Block原语是由被阻塞进程自我调用实现的，而Wakeup原语则是由一个与被唤醒进程相合作或被其他相关的进程调用实现的

引入进程的目的，是为了使多道程序并发执行，以提高资源利用率和系统吞吐量；而引入线程，则是为了减小程序在并发执行时所付出的时空开销，提高操作系统的并发性能。

线程最直接的理解就是“轻量级进程”，它是一个基本的CPU执行单元，也是程序执行流的最小单元，由线程ID、程序计数器、寄存器集合和堆栈组成。线程是进程中的一个实体，是被系统独立调度和分派的基本单位，线程自己不拥有系统资源，只拥有一点在运行中必不可少的资源，但它可与同属一个进程的其他线程共享进程所拥有的全部资源。

引入线程后，进程的内涵发生了改变，进程只作为除CPU以外系统资源的分配单元，线程则作为处理机的分配单元。

在同一进程中，线程的切换不会引起进程切换。在不同进程中进行线程切换,如从一个进程内的线程切换到另一个进程中的线程时，会引起进程切换。

#### 操作系统典型调度算法
##### 先来先服务算法（FCFS）
先来先服务（FCFS）调度算法属于不可剥夺算法。从表面上看，它对所有作业都是公平的，但若一个长作业先到达系统，就会使后面许多短作业等待很长时间，因此它不能作为分时系统和实时系统的主要调度策略。但它常被结合在其他调度策略中使用。例如，在使用优先级作为调度策略的系统中，往往对多个具有相同优先级的进程按FCFS原则处理。

FCFS调度算法的特点是算法简单，但效率低；对长作业比较有利，但对短作业不利（相对SJF和高响应比）；有利于CPU繁忙型作业，而不利于I/O繁忙型作业。

##### 短作业优先（SJF）
短作业优先(SJF)调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。而短进程优先(SPF)调度算法，则是从就绪队列中选择一个估计运行时间最短的进程，将处理机分配给它，使之立即执行，直到完成或发生某事件而阻塞时，才释放处理机。

SJF调度算法也存在不容忽视的缺点：

  1. 该算法对长作业不利，由表2-3和表2-4可知，SJF调度算法中长作业的周转时间会增加。更严重的是，如果有一长作业进入系统的后备队列，由于调度程序总是优先调度那些 (即使是后进来的）短作业，将导致长作业长期不被调度（“饥饿”现象，注意区分“死锁”。后者是系统环形等待，前者是调度策略问题）。
  2. 该算法完全未考虑作业的紧迫程度，因而不能保证紧迫性作业会被及时处理。
  3. 由于作业的长短只是根据用户所提供的估计执行时间而定的，而用户又可能会有意或无意地缩短其作业的估计运行时间，致使该算法不一定能真正做到短作业优先调度。

注意，SJF调度算法的平均等待时间、平均周转时间最少。

##### 优先级调度算法
在作业调度中，优先级调度算法每次从后备作业队列中选择优先级最髙的一个或几个作业，将它们调入内存，分配必要的资源，创建进程并放入就绪队列。在进程调度中，优先级调度算法每次从就绪队列中选择优先级最高的进程，将处理机分配给它，使之投入运行。

根据新的更高优先级进程能否抢占正在执行的进程，可将该调度算法分为：

  1. 非剥夺式优先级调度算法。当某一个进程正在处理机上运行时，即使有某个更为重要或紧迫的进程进入就绪队列，仍然让正在运行的进程继续运行，直到由于其自身的原因而主动让出处理机时（任务完成或等待事件），才把处理机分配给更为重要或紧迫的进程。
  2. 剥夺式优先级调度算法。当一个进程正在处理机上运行时，若有某个更为重要或紧迫的进程进入就绪队列，则立即暂停正在运行的进程，将处理机分配给更重要或紧迫的进程。

而根据进程创建后其优先级是否可以改变，可以将进程优先级分为以下两种：

  1. 静态优先级。优先级是在创建进程时确定的，且在进程的整个运行期间保持不变。确定静态优先级的主要依据有进程类型、进程对资源的要求、用户要求。
  2. 动态优先级。在进程运行过程中，根据进程情况的变化动态调整优先级。动态调整优先级的主要依据为进程占有CPU时间的长短、就绪进程等待CPU时间的长短。

##### 高响应比算法
高响应比优先调度算法主要用于作业调度，该算法是对FCFS调度算法和SJF调度算法的一种综合平衡，同时考虑每个作业的等待时间和估计的运行时间。在每次进行作业调度时，先计算后备作业队列中每个作业的响应比，从中选出响应比最高的作业投入运行。[如图](http://c.biancheng.net/cpp/uploads/allimg/140629/1-140629155214919.png)

根据公式可知：

  1. 当作业的等待时间相同时，则要求服务时间越短，其响应比越高，有利于短作业。
  2. 当要求服务时间相同时，作业的响应比由其等待时间决定，等待时间越长，其响应比越高，因而它实现的是先来先服务。
  3. 对于长作业，作业的响应比可以随等待时间的增加而提高，当其等待时间足够长时，其响应比便可升到很高，从而也可获得处理机。克服了饥饿状态，兼顾了长作业。

##### 时间片轮转算法
时间片轮转调度算法主要适用于分时系统。在这种算法中，系统将所有就绪进程按到达时间的先后次序排成一个队列，进程调度程序总是选择就绪队列中第一个进程执行，即先来先服务的原则，但仅能运行一个时间片，如100ms。在使用完一个时间片后，即使进程并未完成其运行，它也必须释放出（被剥夺）处理机给下一个就绪的进程，而被剥夺的进程返回到就绪队列的末尾重新排队，等候再次运行。

在时间片轮转调度算法中，时间片的大小对系统性能的影响很大。如果时间片足够大，以至于所有进程都能在一个时间片内执行完毕，则时间片轮转调度算法就退化为先来先服务调度算法。如果时间片很小，那么处理机将在进程间过于频繁切换，使处理机的开销增大，而真正用于运行用户进程的时间将减少。因此时间片的大小应选择适当。

时间片的长短通常由以下因素确定：系统的响应时间、就绪队列中的进程数目和系统的处理能力。

##### 多级反馈队列调度算法
多级反馈队列调度算法是时间片轮转调度算法和优先级调度算法的综合和发展，如图2-5 所示。通过动态调整进程优先级和时间片大小，多级反馈队列调度算法可以兼顾多方面的系统目标。例如，为提高系统吞吐量和缩短平均周转时间而照顾短进程；为获得较好的I/O设备利用率和缩短响应时间而照顾I/O型进程；同时，也不必事先估计进程的执行时间。[如图](http://c.biancheng.net/cpp/uploads/allimg/140629/1-140629155KQ11.jpg)

多级反馈队列调度算法的实现思想如下：

  1. 应设置多个就绪队列，并为各个队列赋予不同的优先级，第1级队列的优先级最高，第2级队列次之，其余队列的优先级逐次降低。
  2. 赋予各个队列中进程执行时间片的大小也各不相同，在优先级越高的队列中，每个进程的运行时间片就越小。例如，第2级队列的时间片要比第1级队列的时间片长一倍， ……第i+1级队列的时间片要比第i级队列的时间片长一倍。
  3. 当一个新进程进入内存后，首先将它放入第1级队列的末尾，按FCFS原则排队等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第2级队列的末尾，再同样地按FCFS 原则等待调度执行；如果它在第2级队列中运行一个时间片后仍未完成，再以同样的方法放入第3级队列……如此下去，当一个长进程从第1级队列依次降到第 n 级队列后，在第 n 级队列中便釆用时间片轮转的方式运行。
  4. 仅当第1级队列为空时，调度程序才调度第2级队列中的进程运行；仅当第1 ~ (i-1)级队列均为空时，才会调度第i级队列中的进程运行。如果处理机正在执行第i级队列中的某进程时，又有新进程进入优先级较高的队列（第 1 ~ (i-1)中的任何一个队列），则此时新进程将抢占正在运行进程的处理机，即由调度程序把正在运行的进程放回到第i级队列的末尾，把处理机分配给新到的更高优先级的进程。

#### 进程同步、互斥、临界资源
##### 临界资源
虽然多个进程可以共享系统中的各种资源，但其中许多资源一次只能为一个进程所使用，我们把一次仅允许一个进程使用的资源称为临界资源。许多物理设备都属于临界资源，如打印机等。此外，还有许多变量、数据等都可以被若干进程共享，也属于临界资源。

对临界资源的访问，必须互斥地进行，在每个进程中，访问临界资源的那段代码称为临界区。为了保证临界资源的正确使用，可以把临界资源的访问过程分成四个部分：

  1. 进入区。为了进入临界区使用临界资源，在进入区要检查可否进入临界区，如果可以进入临界区，则应设置正在访问临界区的标志，以阻止其他进程同时进入临界区。
  2. 临界区。进程中访问临界资源的那段代码，又称临界段。
  3. 退出区。将正在访问临界区的标志清除。
  4. 剩余区。代码中的其余部分。

```C++
do {
    entry section;  //进入区
    critical section;  //临界区
    exit section;  //退出区
    remainder section;  //剩余区
} while (true)
```
##### 同步
同步亦称直接制约关系，它是指为完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的工作次序而等待、传递信息所产生的制约关系。进程间的直接制约关系就是源于它们之间的相互合作。
##### 互斥
互斥亦称间接制约关系。当一个进程进入临界区使用临界资源时，另一个进程必须等待, 当占用临界资源的进程退出临界区后，另一进程才允许去访问此临界资源。

例如，在仅有一台打印机的系统中，有两个进程A和进程B，如果进程A需要打印时, 系统已将打印机分配给进程B,则进程A必须阻塞。一旦进程B将打印机释放，系统便将进程A唤醒，并将其由阻塞状态变为就绪状态。

为禁止两个进程同时进入临界区，同步机制应遵循以下准则：

  1. 空闲让进。临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区。
  2. 忙则等待。当已有进程进入临界区时，其他试图进入临界区的进程必须等待。
  3. 有限等待。对请求访问的进程，应保证能在有限时间内进入临界区。
  4. 让权等待。当进程不能进入临界区时，应立即释放处理器，防止进程忙等待。

#### 实现临界区互斥的基本方法
##### 软件实现方法
1. 算法一：单标志法。
  该算法设置一个公用整型变量turn,用于指示被允许进入临界区的进程编号，即若turn=0，则允许P0进程进入临界区。

```C++
// P0进程
while(turn!=0);
critical section;
turn=1;
remainder section;
```

```C++
// P1进程
while(turn!=1);  // 进入区
critical section;  // 临界区
turn = 0;  // 退出区
remainder section;  // 剩余区
```

  该方法可确保只允许一个进程进入临界区。但是，强制两个进程轮流地进入临界区，很容易造成资源利用不充分。例如，当进程p0退出临界区后将turn置为1，以便允许P1进入临界区。但如果进程P1暂时并未要求访问该临界资源，而P0又想再次访问该资源时就无法进入临界区。可见，此算法不能保证实现“空闲让进”的原则。

2. 算法二：双标志法先检查。
  该算法的基本思想是在每一个进程访问临界区资源之前，先查看一下临界资源是否正被访问，若正被访问，该进程需等待；否则，进程才进入自己的临界区。为此，设置了一个数据flag[i]，如第i个元素值为FALSE，表示Pi进程未进入临界区，值为TRUE，表示Pi进程进入临界区。

```C++
// Pi 进程
while(flag[j]);  // ①    
flag[i]=TRUE;  // ③  
critical section;   
flag[i] = FALSE; 
remainder section;
```

```C++
// Pj 进程
while(flag[i]);  // ② 进入区
flag[j] =TRUE;  // ④ 进入区
critical section;  // 临界区
flag[j] = FALSE;  // 退出区
remainder section;  // 剩余区
```

  优点：不用交替进入，可连续使用；缺点：Pi和Pj可能同时进入临界区。按序列①②③④ 执行时，会同时进入临界区（违背“忙则等待”)。即在检查对方flag之后和切换自己flag 之前有一段时间，结果都检查通过。这里的问题出在检查和修改操作不能一次进行。

3. 算法三：双标志法后检查。
  算法二是先检测对方进程状态标志后，再置自己标志，由于在检测和放置中可插入另一个进程到达时的检测操作，会造成两个进程在分别检测后，同时进入临界区。为此，算法三釆用先设置自己标志为TRUE后,再检测对方状态标志，若对方标志为TURE，则进程等待；否则进入临界区。

```C++
// Pi进程
flag[i] =TRUE;
while(flag[j]);
critical section;
flag[i] =FLASE;
remainder section;
```

```C++
// Pj进程
flag[j] =TRUE;  // 进入区
while(flag[i]);  // 进入区
critical section;  // 临界区
flag [j] =FLASE;   // 退出区
remainder section;  // 剩余区
```

  当两个进程几乎同时都想进入临界区时，它们分别将自己的标志值flag设置为TRUE，并且同时检测对方的状态（执行while语句），发现对方也要进入临界区，于是双方互相谦让，结果谁也进不了临界区，从而导致“饥饿”现象。

4. 算法四：Peterson’s Algorithm。
  为了防止两个进程为进入临界区而无限期等待，又设置变量turn，指示不允许进入临界区的进程编号，每个进程在先设置自己标志后再设置turn 标志，不允许另一个进程进入。这时，再同时检测另一个进程状态标志和不允许进入标志，这样可以保证当两个进程同时要求进入临界区，只允许一个进程进入临界区。

```C++
// Pi进程
flag[i]=TURE; turn=j;
while(flag[j]&&turn==j); 
critical section;
flag[i]=FLASE;
remainder section;
```

```C++
// Pj进程
flag[j] =TRUE;turn=i;  // 进入区
while(flag[i]&&turn==i);   // 进入区
critical section;  // 临界区
flag[j]=FLASE;  // 退出区
remainder section;  // 剩余区
```

  本算法的基本思想是算法一和算法三的结合。利用flag解决临界资源的互斥访问，而利用turn解决“饥饿”现象。

##### 硬件实现方法
计算机提供了特殊的硬件指令，允许对一个字中的内容进行检测和修正，或者是对两个字的内容进行交换等。通过硬件支持实现临界段问题的低级方法或称为元方法。

1. 中断屏蔽方法
  当一个进程正在使用处理机执行它的临界区代码时，要防止其他进程再进入其临界区访问的最简单方法是禁止一切中断发生，或称之为屏蔽中断、关中断。因为CPU只在发生中断时引起进程切换，这样屏蔽中断就能保证当前运行进程将临界区代码顺利地执行完，从而保证了互斥的正确实现，然后再执行开中断。其典型模式为：
    …
    关中断;
    临界区;
    开中断;
    …
  这种方法限制了处理机交替执行程序的能力，因此执行的效率将会明显降低。对内核来说，当它执行更新变量或列表的几条指令期间关中断是很方便的，但将关中断的权力交给用户则很不明智，若一个进程关中断之后不再开中断，则系统可能会因此终止。

2. 硬件指令方法
  TestAndSet指令：这条指令是原子操作，即执行该代码时不允许被中断。其功能是读出指定标志后把该标志设置为真。指令的功能描述如下：

```C++
boolean TestAndSet(boolean *lock){
    boolean old;
    old = *lock;
    *lock=true;
    return old;
}
```

  可以为每个临界资源设置一个共享布尔变量lock，表示资源的两种状态：true表示正被占用，初值为false。在进程访问临界资源之前，利用TestAndSet检查和修改标志lock；若有进程在临界区，则重复检查，直到进程退出。利用该指令实现进程互斥的算法描述如下：

```C++
while TestAndSet (& lock);
// 进程的临界区代码段;
lock=false;
// 进程的其他代码
```

  Swap指令：该指令的功能是交换两个字节的内容。其功能描述如下。

```C++
Swap(boolean *a, boolean *b){  
    boolean temp;
    Temp=*a;
    *a = *b;
    *b = temp;
}
```

  应为每个临界资源设置了一个共享布尔变量lock，初值为false；在每个进程中再设置一个局部布尔变量key，用于与lock交换信息。在进入临界区之前先利用Swap指令交换lock 与key的内容，然后检查key的状态；有进程在临界区时，重复交换和检查过程，直到进程退出。利用Swap指令实现进程互斥的算法描述如下：

```C++
key=true;
while(key!=false)
Swap(&lock, &key); 
// 进程的临界区代码段；
lock=false;
// 进程的其他代码；
```

  硬件方法的优点：适用于任意数目的进程，不管是单处理机还是多处理机；简单、容易验证其正确性。可以支持进程内有多个临界区，只需为每个临界区设立一个布尔变量。

  硬件方法的缺点：进程等待进入临界区时要耗费处理机时间，不能实现让权等待。从等待进程中随机选择一个进入临界区，有的进程可能一直选不上，从而导致“饥饿”现象。

#### 信号量：整型、记录型信号量以及利用信号量实现进程互斥和前驱关系
信号量机构是一种功能较强的机制，可用来解决互斥与同步的问题，它只能被两个标准的原语wait(S)和signal(S)来访问，也可以记为“P操作”和“V操作”

##### 整型信号量
整型信号量被定义为一个用于表示资源数目的整型量S，wait和signal操作可描述为：

```C++
wait(S){
    while (S<=0);
    S=S-1;
}
signal(S){
    S=S+1;
}
```

wait操作中，只要信号量S<=0，就会不断地测试。因此，该机制并未遵循“让权等待” 的准则，而是使进程处于“忙等”的状态。

##### 记录型信号量
记录型信号量是不存在“忙等”现象的进程同步机制。除了需要一个用于代表资源数目的整型变量value外，再增加一个进程链表L，用于链接所有等待该资源的进程，记录型信号量是由于釆用了记录型的数据结构得名。记录型信号量可描述为：

```C++
typedef struct{
    int value;
    struct process *L;
} semaphore;
```

相应的wait(S)和signal(S)的操作如下：

```C++
void wait (semaphore S) { //相当于申请资源
    S.value--;
    if(S.value<0) {
        add this process to S.L;
        block(S.L);
    }
}
```

wait操作，S.value--，表示进程请求一个该类资源，当S.value<0时，表示该类资源已分配完毕，因此进程应调用block原语，进行自我阻塞，放弃处理机，并插入到该类资源的等待队列S.L中，可见该机制遵循了“让权等待”的准则。

```C++
void signal (semaphore S) {  //相当于释放资源
    S.value++;
    if(S.value<=0){
        remove a process P from S.L;
        wakeup(P);
    }
}
```

signal操作，表示进程释放一个资源，使系统中可供分配的该类资源数增1，故S.value++。若加1后仍是S.value<=0，则表示在S.L中仍有等待该资源的进程被阻塞，故还应调用wakeup 原语，将S.L中的第一个等待进程唤醒。

##### 利用信号量实现同步
信号量机构能用于解决进程间各种同步问题。设S为实现进程P1、P2同步的公共信号量，初值为0。进程P2中的语句y要使用进程P1中语句x的运行结果，所以只有当语句x执行完成之后语句y才可以执行。其实现进程同步的算法如下：

```C++
semaphore S = 0;  //初始化信号量
P1 ( ) {
    // …
    x;  //语句x
    V(S);  //告诉进程P2,语句乂已经完成
}
P2()）{
    // …
    P(S) ;  //检查语句x是否运行完成
    y;  // 检查无误，运行y语句
    // …
}
```

##### 利用信号量实现进程互斥
设S为实现进程Pl、P2互斥的信号量，由于每次只允许一个进程进入临界区，所以S的初值应为1（即可用资源数为1)。只需把临界区置于P(S)和V(S)之间，即可实现两进程对临界资源的互斥访问。其算法如下：

```C++
semaphore S = 1;  //初化信号量
P1 ( ) {
    // …
    P(S);  // 准备开始访问临界资源，加锁
    // 进程P1的临界区
    V(S);  // 访问结束，解锁
    // …
}
P2() {
    // …
    P(S); //准备开始访问临界资源，加锁
    // 进程P2的临界区；
    V(S);  // 访问结束，解锁
    // …
}
```

互斥的实现是不同进程对同一信号量进行P、V操作，一个进程在成功地对信号量执行了 P操作后进入临界区，并在退出临界区后，由该进程本身对该信号量执行V操作,表示当前没有进程进入临界区，可以让其他进程进入。

##### 利用信号量实现前驱关系
信号量也可以用来描述程序之间或者语句之间的前驱关系。图2-8给出了一个前驱图，其中S1, S2, S3, …, S6是最简单的程序段（只有一条语句）。为使各程序段能正确执行，应设置若干个初始值为“0”的信号量。例如，为保证S1 -> S2、 S1 -> S3的前驱关系，应分别设置信号量a1、a2。同样，为了保证 S2 -> S4、S2 ->S5、S3 -> S6、S4 -> S6、S5 -> S6,应设置信号量bl、b2、c、d、e。[如图](http://c.biancheng.net/cpp/uploads/allimg/140629/1-140629220313125.png)

```C++
semaphore  al=a2=bl=b2=c=d=e=0;  //初始化信号量
S1() {
    // …
    V(al);  V(a2) ;  //S1已经运行完成
}
S2() {
    P(a1);  //检查S1是否运行完成
    // …
    V(bl); V(b2); // S2已经运行完成
}
S3() {
    P(a2);  //检查S1是否已经运行完成
    // …
    V(c);  //S3已经运行完成
}
S4() {
    P(b1);  //检查S2是否已经运行完成
    // …
    V(d);  //S4已经运行完成
}
S5() {
    P(b2);  //检查S2是否已经运行完成
    // …
    V(e);  // S5已经运行完成
}
S6() {
    P(c);  //检查S3是否已经运行完成
    P(d);  //检查S4是否已经运行完成
    P(e);  //检查S5是否已经运行完成
    // …;
}
```

#### 管程：管程的定义、组成及基本特性
管程可以看做一个软件模块，它是将共享的变量和对于这些共享变量的操作封装起来，形成一个具有一定接口的功能模块，进程可以调用管程来实现进程级别的并发控制。
进程只能互斥得使用管程，即当一个进程使用管程时，另一个进程必须等待。当一个进程使用完管程后，它必须释放管程并唤醒等待管程的某一个进程。
在管程入口处的等待队列称为入口等待队列，由于进程会执行唤醒操作，因此可能有多个等待使用管程的队列，这样的队列称为紧急队列，它的优先级高于等待队列。

##### 管程的组成
1. 局部于管程的共享结构数据说明。
2. 对该数据结构进行操作的一组过程。
3. 对局部于管程的共享数据设置初始值的语句。

##### 管程的基本特性
1. 模块化。
  管程是一个基本的软件模块，可以被单独编译。
2. 抽象数据类型。
  管程中封装了数据及对于数据的操作，这点有点像面向对象编程语言中的类。
3. 信息隐藏。
  管程外的进程或其他软件模块只能通过管程对外的接口来访问管程提供的操作，管程内部的实现细节对外界是透明的。
4. 使用的互斥性。
  任何一个时刻，管程只能由一个进程使用。进入管程时的互斥由编译器负责完成。

##### enter过程、leave过程、条件型变量c、wait(c) 、signal(c)
1. enter过程
 一个进程进入管程前要提出申请，一般由管程提供一个外部过程--enter过程。如Monitor.enter()表示进程调用管程Monitor外部过程enter进入管程。
2. leave过程
  当一个进程离开管程时，如果紧急队列不空，那么它就必须负责唤醒紧急队列中的一个进程，此时也由管程提供一个外部过程—leave过程，如Monitor.leave()表示进程调用管程Monitor外部过程leave离开管程。
3. 条件型变量c
  条件型变量c实际上是一个指针，它指向一个等待该条件的PCB队列。如notfull表示缓冲区不满，如果缓冲区已满，那么将要在缓冲区写入数据的进程就要等待notfull，即wait(notfull)。相应的，如果一个进程在缓冲区读数据，当它读完一个数据后，要执行signal(notempty)，表示已经释放了一个缓冲区单元。
4. wait(c)
  wait(c)表示为进入管程的进程分配某种类型的资源，如果此时这种资源可用，那么进程使用，否则进程被阻塞，进入紧急队列。
5. signal(c)
  signal(c)表示进入管程的进程使用的某种资源要释放，此时进程会唤醒由于等待这种资源而进入紧急队列中的第一个进程。

#### 死锁
死锁是指多个进 程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都将无法向前推进。
只有对不可剥夺资源的竞争 才可能产生死锁，对可剥夺资源的竞争是不会引起死锁的。
##### 死锁产生的必要条件
  1. 互斥条件：进程要求对所分配的资源（如打印机）进行排他性控制，即在一段时间内某 资源仅为一个进程所占有。此时若有其他进程请求该资源，则请求进程只能等待。
  2. 不剥夺条件：进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能 由获得该资源的进程自己来释放（只能是主动释放)。
  3. 请求和保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源 已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。
  4. 循环等待条件：存在一种进程资源的循环等待链，链中每一个进程已获得的资源同时被 链中下一个进程所请求。循环等待只是死锁的必要条件。

#####  银行家算法
操作系统按照银行家制定的规则为进程分配资源，当进程首次申请资源时，要测试该进程对资源的最大需求量，如果系统现存的资源可以满足它的最大需求量则按当前的申请量分配资源，否则就推迟分配。当进程在执行中继续申请资源时，先测试该进程已占用的资源数与本次申请的资源数之和是否超过了该进程对资源的最大需求量。若超过则拒绝分配资源，若没有超过则再测试系统现存的资源能否满足该进程尚需的最大资源量，若能满足则按当前的申请量分配资源，否则也要推迟分配。

  1. 数据结构描述
	可利用资源矢量Available：含有m个元素的歎组，其中的每一个元素代表一类可用的资源数目。Available[j]=K，则表示系统中现有Rj类资源K个。
    最大需求矩阵Max：为n*m矩阵，定义了系统中n个进程中的每一个进程对m类资源的最大需求。Max[i, j]=K，则表示进程i需要Rj类资源的最大数目为K。
    分配矩阵Allocation：为n*m矩阵，定义了系统中每一类资源当前已分配给每一进程的资源数。Allocation[i, j]= K，则表示进程i当前已分得Rj类资源的数目为K。
    需求矩阵Need：为n*m矩阵，表示每个进程尚需的各类资源数。Need[i, j]=K，则表示进程i还需要Rj类资源的数目为K。
    上述三个矩阵间存在下述关系：
    Need[i, j] = Max[i, j] - Allocation[i, j] 

  2. 银行家算法描述
  	设Requesti是进程Pi的请求矢量，如果Requesti[j]K，表示进程Pi需要Rj类资源K个。当Pi发出资源请求后，系统按下述步骤进行检查：
  		1） 如果Requesti[j] <= Need[i, j]，便转向步骤②；否则认为出错，因为它所需要的资源数已超过它所宣布的最大值。
        2） 如果Requesti[j] <= Available[j]，便转向步骤③;否则，表示尚无足够资源，Pi须等待。
		3） 系统试探着把资源分配给进程Pi，并修改下面数据结构中的数值：
```C++
Available[j] = Available[j] - Requesti[j];
Allocation[i, j] = Allocation[i, j] + Requesti[ j];
Need[i, j] = Need[i, j] - Requesti[j];
```
		4) 系统执行安全性算法，检查此次资源分配后，系统是否处于安全状态。若安全，才正式将资源分配给进程Pi，以完成本次分配；否则，将本次的试探分配作废，恢复原来的资源分配状态，让进程Pi等待。

  3. 安全性算法
  	1) 设置两个矢量。工作矢量Work；它表示系统可提供给进程继续运行所需的各类资源数目，它含有所个元素，在执行安全算法开始时，Work=Available; Finish：它表示系统是否有足够的资源分配给进程，使之运行完成。开始时 Finish[i]=false；当有足够资源分配给进程 Pi 时，再令 Finish[i]=true。
  	2) 从进程集合中找到一个能满足下述条件的进程：Finish[i]=false;    Need[i, j]<=Work[j]; 若找到，执行下一步骤，否则，执行步骤4。
  	3) 当进程Pi获得资源后，可顺利执行，直至完成，并释放出分配给它的资源，故应执行：
```C++
Work[j]=Work[j]+Allocation[i, j];
Finish[i]=true;
go to step <2>;
```
	4) 如果所有进程的Finish[i]=true都满足，则表示系统处于安全状态；否则，系统处于不安全状态。

##### 死锁的解除
  1. 资源剥夺法。挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程。但应防止被挂起的进程长时间得不到资源，而处于资源匮乏的状态。
  2. 撤销进程法。强制撤销部分、甚至全部死锁进程并剥夺这些进程的资源。撤销的原则可以按进程优先级和撤销进程代价的高低进行。
  3. 进程回退法。让一（多）个进程回退到足以回避死锁的地步，进程回退时自愿释放资源而不是被剥夺。要求系统保持进程的历史信息，设置还原点。

“饥饿”并不表示系统一定死锁，但至少有一个进程的执行被无限期推迟。“饥饿”与死锁的主要差别有：
  
  - 进入“饥饿”状态的进程可以只有一个，而由于循环等待条件而进入死锁状态的进程却必须大于或等于两个。
  - 处于“饥饿”状态的进程可以是一个就绪进程，如静态优先权调度算法时的低优先权进程，而处于死锁状态的进程则必定是阻塞进程。 

进程同步、互斥的区别和联系:

  并发进程的执行会产生相互制约的关系：一种是进程之间竞争使用临界资源，只能让它们逐个使用，这种现象称为互斥，是一种竞争关系；另一种是进程之间协同完成任务，在关键点上等待另一个进程发来的消息，以便协同一致，是一种协作关系。

### 内存管理
#### 内存管理概念
内存管理的功能有：

  1. 内存空间的分配与回收：由操作系统完成主存储器空间的分配和管理，使程序员摆脱存储分配的麻烦，提高编程效率。
  2. 地址转换：在多道程序环境下，程序中的逻辑地址与内存中的物理地址不可能一致，因此存储管理必须提供地址变换功能，把逻辑地址转换成相应的物理地址。
  3. 内存空间的扩充：利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存。
  4. 存储保护：保证各道作业在各自的存储空间内运行，.互不干扰。

##### 程序装入和链接
创建进程首先要将程序和数据装入内存。将用户源程序变为可在内存中执行的程序，通常需要以下几个步骤：[如图](http://c.biancheng.net/cpp/uploads/allimg/140630/1-1406301T554425.jpg)

  1. 编译：由编译程序将用户源代码编译成若干个目标模块。
  2. 链接：由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完整的装入模块。
  3. 装入：由装入程序将装入模块装入内存运行。

程序的链接有以下三种方式：

  1. 静态链接：在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的可执行程序，以后不再拆开。
  2. 装入时动态链接：将用户源程序编译后所得到的一组目标模块，在装入内存时，釆用边装入边链接的链接方式。
  3. 运行时动态链接：对某些目标模块的链接，是在程序执行中需要该目标模块时，才对它进行的链接。其优点是便于修改和更新，便于实现对目标模块的共享。

内存的装入模块在装入内存时，同样有以下三种方式：

  1. 绝对装入。在编译时，如果知道程序将驻留在内存的某个位置，编译程序将产生绝对地址的目标代码。绝对装入程序按照装入模块中的地址，将程序和数据装入内存。由于程序中的逻辑地址与实际内存地址完全相同，故不需对程序和数据的地址进行修改。绝对装入方式只适用于单道程序环境。
  2. 可重定位装入。在多道程序环境下，多个目标模块的起始地址通常都是从0开始，程序中的其他地址都是相对于起始地址的,此时应釆用可重定位装入方式。根据内存的当前情况，将装入模块装入到内存的适当位置。装入时对目标程序中指令和数据的修改过程称为重定位，地址变换通常是在装入时一次完成的，所以又称为静态重定位。静态重定位的特点是在一个作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，就不能装入该作业。此外，作业一旦进入内存后，在整个运行期间不能在内存中移动，也不能再申请内存空间。
  3. 动态运行时装入，也称为动态重定位，程序在内存中如果发生移动，就需要釆用动态的装入方式。装入程序在把装入模块装入内存后，并不立即把装入模块中的相对地址转换为绝对地址，而是把这种地址转换推迟到程序真正要执行时才进行。因此，装入内存后的所有地址均为相对地址。这种方式需要一个重定位寄存器的支持。动态重定位的特点是可以将程序分配到不连续的存储区中；在程序运行之前可以只装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存；便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间。

##### 内存保护
重定位寄存器含最小的物理地址值，界地址寄存器含逻辑地址值。每个逻辑地址值必须小于界地址寄存器；内存管理机构动态地将逻辑地址与界地址寄存器进行比较，如果未发生地址越界，则加上重定位寄存器的值后映射成物理地址，再送交内存单元，[如图](http://c.biancheng.net/cpp/uploads/allimg/140630/1-1406301UQE16.jpg)。 

#### 内存覆盖于内存交行
##### 内存覆盖
覆盖的基本思想是：由于程序运行时并非任何时候都要访问程序及数据的各个部分（尤其是大程序），因此可以把用户空间分成一个固定区和若干个覆盖区。将经常活跃的部分放在固定区，其余部分按调用关系分段。首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统再将其调入覆盖区，替换覆盖区中原有的段。

##### 内存交换
交换（对换）的基本思想是，把处于等待状态（或在CPU调度原则下被剥夺运行权利） 的程序从内存移到辅存，把内存空间腾出来，这一过程又叫换出；把准备好竞争CPU运行的程序从辅存移到内存，这一过程又称为换入。中级调度就是釆用交换技术。

有关交换需要注意以下几个问题：
  
  1. 交换需要备份存储，通常是快速磁盘。它必须足够大，并且提供对这些内存映像的直接访问。
  2. 为了有效使用CPU，需要每个进程的执行时间比交换时间长，而影响交换时间的主要是转移时间。转移时间与所交换的内存空间成正比。
  3. 如果换出进程，必须确保该进程是完全处于空闲状态。
  4. 交换空间通常作为磁盘的一整块，且独立于文件系统，因此使用就可能很快。
  5. 交换通常在有许多进程运行且内存空间吃紧时开始启动，而系统负荷降低就暂停。
  6. 普通的交换使用不多，但交换策略的某些变种在许多系统中（如UNIX系统）仍发挥作用。

交换技术主要是在不同进程（或作业）之间进行，而覆盖则用于同一个程序或进程中。由于覆盖技术要求给出程序段之间的覆盖结构，使得其对用户和程序员不透明，所以对于主存无法存放用户程序的矛盾，现代操作系统是通过虚拟内存技术来解决的，覆盖技术则已成为历史；而交换技术在现代操作系统中仍具有较强的生命力。

#### 内存连续分配管理方式
连续分配方式，是指为一个用户程序分配一个连续的内存空间。它主要包括单一连续分配、固定分区分配和动态分区分配。

##### 单一连续分配
内存在此方式下分为系统区和用户区，系统区仅提供给操作系统使用，通常在低地址部分；用户区是为用户提供的、除系统区之外的内存空间。这种方式无需进行内存保护。

这种方式的优点是简单、无外部碎片，可以釆用覆盖技术，不需要额外的技术支持。缺点是只能用于单用户、单任务的操作系统中，有内部碎片，存储器的利用率极低。

##### 固定分区分配
固定分区分配是最简单的一种多道程序存储管理方式，它将用户内存空间划分为若干个固定大小的区域，每个分区只装入一道作业。当有空闲分区时，便可以再从外存的后备作业队列中,选择适当大小的作业装入该分区，如此循环。

为便于内存分配，通常将分区按大小排队，并为之建立一张分区说明表，其中各表项包括每个分区的起始地址、大小及状态（是否已分配）。当有用户程序要装入时，便检索该表，以找到合适的分区给予分配并将其状态置为”已分配”；未找到合适分区则拒绝为该用户程序分配内存。[如图](http://c.biancheng.net/cpp/uploads/allimg/140630/1-140630210313396.png)

这种分区方式存在两个问题：一是程序可能太大而放不进任何一个分区中，这时用户不得不使用覆盖技术来使用内存空间；二是主存利用率低，当程序小于固定分区大小时，也占用了一个完整的内存分区空间，这样分区内部有空间浪费，这种现象称为内部碎片。固定分区是可用于多道程序设计最简单的存储分配，无外部碎片，但不能实现多进程共享一个主存区，所以存储空间利用率低。

##### 动态分区分配
动态分区分配又称为可变分区分配，是一种动态划分内存的分区方法。这种分区方法不预先将内存划分，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。因此系统中分区的大小和数目是可变的。[如图](http://c.biancheng.net/cpp/uploads/allimg/140630/1-140630211AT00.jpg)

动态分区在开始分配时是很好的，但是之后会导致内存中出现许多小的内存块。随着时间的推移，内存中会产生越来越多的碎片,内存的利用率随之下降。这些小的内存块称为外部碎片，指在所有分区外的存储空间会变成越来越多的碎片，这与固定分区中的内部碎片正好相对。克服外部碎片可以通过紧凑（Compaction)技术来解决，就是操作系统不时地对进程进行移动和整理。但是这需要动态重定位寄存器的支持，且相对费时。紧凑的过程实际上类似于Windows系统中的磁盘整理程序，只不过后者是对外存空间的紧凑。

在进程装入或换入主存时，如果内存中有多个足够大的空闲块，操作系统必须确定分配哪个内存块给进程使用，这就是动态分区的分配策略，考虑以下几种算法：
  
  1. 首次适应(First Fit)算法：空闲分区以地址递增的次序链接。分配内存时顺序查找，找到大小能满足要求的第一个空闲分区。
  2. 最佳适应(Best Fit)算法：空闲分区按容量递增形成分区链，找到第一个能满足要求的空闲分区。
  3. 最坏适应(Worst Fit)算法：又称最大适应(Largest Fit)算法，空闲分区以容量递减的次序链接。找到第一个能满足要求的空闲分区，也就是挑选出最大的分区。
  4. 邻近适应(Next Fit)算法：又称循环首次适应算法，由首次适应算法演变而成。不同之处是分配内存时从上次查找结束的位置开始继续查找。

首次适应算法不仅是最简单的，而且通常也是最好和最快的。不过，首次适应算法会使得内存的低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。
邻近适应算法试图解决这个问题，但实际上，它常常会导致在内存的末尾分配空间（因为在一遍扫描中，内存前面部分使用后再释放时，不会参与分配)，分裂成小碎片。它通常比首次适应算法的结果要差。
最佳适应算法虽然称为“最佳”，但是性能通常很差，因为每次最佳的分配会留下很小的难以利用的内存块，它会产生最多的外部碎片。
最坏适应算法与最佳适应算法相反，选择最大的可用块，这看起来最不容易产生碎片，但是却把最大的连续内存划分开，会很快导致没有可用的大的内存块，因此性能也非常差。

#### 内存非连续分配管理方式
非连续分配允许一个程序分散地装入到不相邻的内存分区中，根据分区的大小是否固定分为分页存储管理方式和分段存储管理方式。
分页存储管理方式中，又根据运行作业时是否要把作业的所有页面都装入内存才能运行分为基本分页存储管理方式和请求分页存储管理方式。

##### 基本分页存储管理方式
固定分区会产生内部碎片，动态分区会产生外部碎片，这两种技术对内存的利用率都比较低。我们希望内存的使用能尽量避免碎片的产生，这就引入了分页的思想：把主存空间划分为大小相等且固定的块，块相对较小，作为主存的基本单位。每个进程也以块为单位进行划分，进程在执行时，以块为单位逐个申请主存中的块空间。
分页的方法从形式上看，像分区相等的固定分区技术，分页管理不会产生外部碎片。但它又有本质的不同点：块的大小相对分区要小很多，而且进程也按照块进行划分，进程运行时按块申请主存可用空间并执行。这样，进程只会在为最后一个不完整的块申请一个主存块空间时，才产生主存碎片，所以尽管会产生内部碎片，但是这种碎片相对于进程来说也是很小的，每个进程平均只产生半个块大小的内部碎片（也称页内碎片）。

1. 分页存储的几个基本概念
  
  - 页面和页面大小。进程中的块称为页(Page)，内存中的块称为页框（Page Frame，或页帧）。外存也以同样的单位进行划分，直接称为块(Block)。进程在执行时需要申请主存空间，就是要为每个页面分配主存中的可用页框，这就产生了页和页框的一一对应。
  - 逻辑地址结构。地址结构包含两部分：前一部分为页号P，后一部分为页内偏移量W。地址长度为32 位，其中0~11位为页内地址，即每页大小为4KB；12~31位为页号，地址空间最多允许有220页。[如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F10031342c.png)
  - 页表。为了便于在内存中找到进程的每个页面所对应的物理块，系统为每个进程建立一张页表，记录页面在内存中对应的物理块号，页表一般存放在内存中。在配置了页表后，进程执行时，通过查找该表，即可找到每页在内存中的物理块号。可见，页表的作用是实现从页号到物理块号的地址映射，[如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F1003A14D.jpg)

2. 基本地址变换机构

地址变换机构的任务是将逻辑地址转换为内存中物理地址，地址变换是借助于页表实现的。
在系统中通常设置一个页表寄存器(PTR)，存放页表在内存的始址F和页表长度M。进程未执行时，页表的始址和长度存放在进程控制块中，当进程执行时，才将页表始址和长度存入页表寄存器。设页面大小为L，逻辑地址A到物理地址E的变换过程如下：(整个地址变换过程均是由硬件自动完成的, [如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F1004005H3.jpg))

  1. 计算页号P(P=A/L)和页内偏移量W (W=A%L)。
  2. 比较页号P和页表长度M，若P >= M，则产生越界中断，否则继续执行。
  3. 页表中页号P对应的页表项地址 = 页表起始地址F + 页号P * 页表项长度，取出该页表项内容b，即为物理块号。
  4. 计算E=b*L+W，用得到的物理地址E去访问内存。

3. 具有快表的地址变换机构

在地址变换机构中增设了一个具有并行查找能力的高速缓冲存储器——快表，又称联想寄存器(TLB)，用来存放当前访问的若干页表项，以加速地址变换的过程。与此对应，主存中的页表也常称为慢表，[如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F100444V53.jpg)
在具有快表的分页机制中，地址的变换过程：

  1. CPU给出逻辑地址后，由硬件进行地址转换并将页号送入高速缓存寄存器，并将此页号与快表中的所有页号进行比较。
  2. 如果找到匹配的页号，说明所要访问的页表项在快表中，则直接从中取出该页对应的页框号，与页内偏移量拼接形成物理地址。这样，存取数据仅一次访存便可实现。
  3. 如果没有找到，则需要访问主存中的页表，在读出页表项后，应同时将其存入快表，以便后面可能的再次访问。但若快表已满，则必须按照一定的算法对旧的页表项进行替换。

一般快表的命中率可以达到90%以上，这样，分页带来的速度损失就降低到10%以下。快表的有效性是基于著名的局部性原理.

4. 两级页表

第二个问题：由于引入了分页管理，进程在执行时不需要将所有页调入内存页框中，而只要将保存有映射关系的页表调入内存中即可。但是我们仍然需要考虑页表的大小。以32 位逻辑地址空间、页面大小4KB、页表项大小4B为例，若要实现进程对全部逻辑地址空间的映射，则每个进程需要2^20，约100万个页表项。也就是说，每个进程仅页表这一项就需要4MB主存空间，这显然是不切实际的。将页表映射的思想进一步延伸，就可以得到二级分页，在进程执行时，只需要将这1页的上一级页表调入内存即可，进程的页表和进程本身的页面，可以在后面的执行中再调入内存。
[如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F1005205M0.jpg)，这是Intel处理器80x86系列的硬件分页的地址转换过程。在32位系统中，全部32位逻辑地址空间可以分为2^20(4GB/4KB)个页面。这些页面可以再进一步建立顶级页表，需要2^10个顶级页表项进行索引，这正好是一页的大小，所以建立二级页表即可。

进程需要读逻辑地址0x20021406中的字节内容，这个逻辑地址按如下进行处理：

  - 逻辑地址： 0x20021406 (0010 0000 0000 0010 0001 0100 0000 0110 B)
  - 顶级页表字段：0x80 (00 1000 0000 B)
  - 二级页表字段：0x21 (00 0010 0001B)
  - 页内偏移量字段：0x406  (0100 0000 0110B)

顶级页表字段的0x80用于选择顶级页表的第0x80表项，此表项指向和该进程的页相关的二级页表；二级页表字段0x21用于选择二级页表的第0x21表项，此表项指向包含所需页的页框；最后的页内偏移量字段0x406用于在目标页框中读取偏移量为0x406中的字节。

##### 基本分段存储管理方式
分页管理方式是从计算机的角度考虑设计的，以提高内存的利用率，提升计算机的性能, 且分页通过硬件机制实现，对用户完全透明；而分段管理方式的提出则是考虑了用户和程序员，以满足方便编程、信息保护和共享、动态增长及动态链接等多方面的需要。

1. 分段

  段式管理方式按照用户进程中的自然段划分逻辑空间。例如，用户进程由主程序、两个子程序、栈和一段数据组成，于是可以把这个用户进程划分为5个段，每段从0 开始编址，并分配一段连续的地址空间。其逻辑地址由段号S与段内偏移量W两部分组成。

2. 段表

  每个进程都有一张逻辑空间与内存空间映射的段表，其中每一个段表项对应进程的一个段，段表项记录该段在内存中的起始地址和段的长度。[如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F1010615163.jpg)

3. 地址变换机构

  [如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F1011015B6.jpg)，为实现进程从逻辑地址到物理地址的变换功能，在系统中设置了段表寄存器，用于存放段表始址F和段表长度M。其从逻辑地址A到物理地址E之间的地址变换过程如下：
  
    1. 从逻辑地址A中取出前几位为段号S，后几位为段内偏移量W。
    2. 比较段号S和段表长度M，若S多M，则产生越界中断，否则继续执行。
    3. 段表中段号S对应的段表项地址 = 段表起始地址F + 段号S * 段表项长度，取出该段表项的前几位得到段长C。若段内偏移量>=C，则产生越界中断，否则继续执行。
    4. 取出段表项中该段的起始地址b，计算 E = b + W，用得到的物理地址E去访问内存。

##### 段页式管理方式
页式存储管理能有效地提高内存利用率，而分段存储管理能反映程序的逻辑结构并有利于段的共享。如果将这两种存储管理方法结合起来，就形成了段页式存储管理方式。
在段页式系统中，作业的地址空间首先被分成若干个逻辑段，每段都有自己的段号，然后再将每一段分成若干个大小固定的页。对内存空间的管理仍然和分页存储管理一样，将其分成若干个和页面大小相同的存储块，对内存的分配以存储块为单位，[如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F1011A01S.jpg)
在段页式系统中，作业的逻辑地址分为三部分：段号、页号和页内偏移量.

在进行地址变换时，首先通过段表查到页表起始地址，然后通过页表找到页帧号，最后形成物理地址。进行一次访问实际需要三次访问主存，这里同样可以使用快表以加快查找速度，其关键字由段号、页号组成，值是对应的页帧号和保护码。[如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F10123342B.jpg)

#### 虚拟内存的概念、特征以及虚拟内存的实现
##### 局部性原理
局部性原理表现在以下两个方面：

  1. 时间局部性：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
  2. 空间局部性：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。

时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。虚拟内存技术实际上就是建立了 “内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存。  
##### 虚拟存储器的定义和特征
虚拟存储器有以下三个主要特征：

  1. 多次性，是指无需在作业运行时一次性地全部装入内存，而是允许被分成多次调入内存运行。
  2. 对换性，是指无需在作业运行时一直常驻内存，而是允许在作业的运行过程中，进行换进和换出。
  3. 虚拟性，是指从逻辑上扩充内存的容量，使用户所看到的内存容量，远大于实际的内存容量。

##### 虚拟内存技术的实现
虚拟内存的实需要建立在离散分配的内存管理方式的基础上。虚拟内存的实现有以下三种方式：
  
  1. 请求分页存储管理。
  2. 请求分段存储管理。
  3. 请求段页式存储管理。

不管哪种方式，都需要有一定的硬件支持。一般需要的支持有以下几个方面：
  
  1. 一定容量的内存和外存。
  2. 页表机制（或段表机制），作为主要的数据结构。
  3. 中断机构，当用户程序要访问的部分尚未调入内存，则产生中断。
  4. 地址变换机构，逻辑地址到物理地址的变换。

#### 请求分页管理方式实现虚拟内存
请求分页系统建立在基本分页系统基础之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。
##### 页表机制
请求分页系统的页表机制不同于基本分页系统，请求分页系统在一个作业运行之前不要求全部一次性调入内存，因此在作业的运行过程中，必然会出现要访问的页面不在内存的情况，为此，在请求页表项中增加了四个字段，[如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F10202531Y.png)
增加的四个字段说明如下：

  1. 状态位P：用于指示该页是否已调入内存，供程序访问时参考。
  2. 访问字段A：用于记录本页在一段时间内被访问次数，或记录本页最近己有多长时间未被访问，供置换算法换出页面时参考。
  3. 修改位M：标识该页在调入内存后是否被修改过。
  4. 外存地址：用于指出该页在外存上的地址，通常是物理块号，供调入该页时参考。

##### 缺页中断机构
在请求分页系统中，每当所要访问的页面不在内存时，便产生一个缺页中断，请求操作系统将所缺的页调入内存。此时应将缺页的进程阻塞（调页完成唤醒)，如果内存中有空闲块，则分配一个块，将要调入的页装入该块，并修改页表中相应页表项，若此时内存中没有空闲块，则要淘汰某页（若被淘汰页在内存期间被修改过，则要将其写回外存)。
##### 地址变换机构
[如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F102004L08.jpg)，在进行地址变换时，先检索快表：

  1. 若找到要访问的页，便修改页表项中的访问位（写指令则还须重置修改位)，然后利用页表项中给出的物理块号和页内地址形成物理地址。
  2. 若未找到该页的页表项，应到内存中去查找页表，再对比页表项中的状态位P，看该页是否已调入内存，未调入则产生缺页中断，请求从外存把该页调入内存。

#### 页面置换算法
进程运行时，若其访问的页面不在内存而需将其调入，但内存已无空闲空间时，就需要从内存中调出一页程序或数据，送入磁盘的对换区。选择调出页面的算法就称为页面置换算法。好的页面置换算法应有较低的页面更换频率，也就是说，应将以后不会再访问或者以后较长时间内不会再访问的页面先调出。
##### 最佳置换算法(OPT)
最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。
##### 先进先出(FIFO)页面置换算法
优先淘汰最早进入内存的页面，亦即在内存中驻留时间最久的页面。该算法实现简单，只需把调入内存的页面根据先后次序链接成队列，设置一个指针总指向最早的页面。但该算法与进程实际运行时的规律不适应，因为在进程中，有的页面经常被访问。
##### 最近最久未使用(LRU)置换算法
选择最近最长时间未访问过的页面予以淘汰，它认为过去一段时间内未访问过的页面，在最近的将来可能也不会被访问。该算法为每个页面设置一个访问字段，来记录页面自上次被访问以来所经历的时间，淘汰页面时选择现有页面中值最大的予以淘汰。
LRU性能较好，但需要寄存器和栈的硬件支持。LRU是堆栈类的算法。理论上可以证明，堆栈类算法不可能出现Belady异常。FIFO算法基于队列实现，不是堆栈类算法。
##### 时钟(CLOCK)置换算法
简单的CLOCK算法是给每一帧关联一个附加位，称为使用位。当某一页首次装入主存时，该帧的使用位设置为1;当该页随后再被访问到时，它的使用位也被置为1。对于页替换算法，用于替换的候选帧集合看做一个循环缓冲区，并且有一个指针与之相关联。当某一页被替换时，该指针被设置成指向缓冲区中的下一帧。当需要替换一页时，操作系统扫描缓冲区，以查找使用位被置为0的一帧。每当遇到一个使用位为1的帧时，操作系统就将该位重新置为0；如果在这个过程开始时，缓冲区中所有帧的使用位均为0，则选择遇到的第一个帧替换；如果所有帧的使用位均为1,则指针在缓冲区中完整地循环一周，把所有使用位都置为0，并且停留在最初的位置上，替换该帧中的页。由于该算法循环地检查各页面的情况，故称为CLOCK算法，又称为最近未用(Not Recently Used, NRU)算法。
CLOCK算法的性能比较接近LRU，而通过增加使用的位数目，可以使得CLOCK算法更加高效。在使用位的基础上再增加一个修改位，则得到改进型的CLOCK置换算法。这样，每一帧都处于以下四种情况之一：

  1. 最近未被访问，也未被修改(u=0, m=0)。
  2. 最近被访问，但未被修改(u=1, m=0)。
  3. 最近未被访问，但被修改(u=0, m=1)。
  4. 最近被访问，被修改(u=1, m=1)。

算法执行如下操作步骤：
  
  1. 从指针的当前位置开始，扫描帧缓冲区。在这次扫描过程中，对使用位不做任何修改。选择遇到的第一个帧(u=0, m=0)用于替换。
  2. 如果第1)步失败，则重新扫描，查找(u=0, m=1)的帧。选择遇到的第一个这样的帧用于替换。在这个扫描过程中，对每个跳过的帧，把它的使用位设置成0。
  3. 如果第2)步失败，指针将回到它的最初位置，并且集合中所有帧的使用位均为0。重复第1步，并且如果有必要，重复第2步。这样将可以找到供替换的帧。

改进型的CLOCK算法优于简单CLOCK算法之处在于替换时首选没有变化的页。由于修改过的页在被替换之前必须写回，因而这样做会节省时间。

#### 页面分配策略：驻留集大小、调入页面的时机以及从何处调入页面
##### 驻留集大小
对于分页式的虚拟内存，在准备执行时，不需要也不可能把一个进程的所有页都读取到主存，因此，操作系统必须决定读取多少页。也就是说，给特定的进程分配多大的主存空间，这需要考虑以下几点：

  1. 分配给一个进程的存储量越小，在任何时候驻留在主存中的进程数就越多，从而可以提高处理机的时间利用效率。
  2. 如果一个进程在主存中的页数过少，尽管有局部性原理，页错误率仍然会相对较高。
  3. 如桌页数过多，由于局部性原理，给特定的进程分配更多的主存空间对该进程的错误率没有明显的影响。

基于这些因素，现代操作系统通常釆用三种策略：

  1. 固定分配局部置换。它为每个进程分配一定数目的物理块，在整个运行期间都不改变。若进程在运行中发生缺页，则只能从该进程在内存中的页面中选出一页换出，然后再调入需要的页面。实现这种策略难以确定为每个进程应分配的物理块数目：太少会频繁出现缺页中断，太多又会使CPU和其他资源利用率下降。
  2. 可变分配全局置换。这是最易于实现的物理块分配和置换策略，为系统中的每个进程分配一定数目的物理块,操作系统自身也保持一个空闲物理块队列。当某进程发生缺页时，系统从空闲物理块队列中取出一个物理块分配给该进程，并将欲调入的页装入其中。
  3. 可变分配局部置换。它为每个进程分配一定数目的物理块，当某进程发生缺页时，只允许从该进程在内存的页面中选出一页换出，这样就不会影响其他进程的运行。如果进程在运行中频繁地缺页，系统再为该进程分配若干物理块，直至该进程缺页率趋于适当程度； 反之，若进程在运行中缺页率特别低，则可适当减少分配给该进程的物理块。

##### 调入页面的时机
为确定系统将进程运行时所缺的页面调入内存的时机，可釆取以下两种调页策略：
  
  1. 预调页策略。根据局部性原理，一次调入若干个相邻的页可能会比一次调入一页更高效。但如果调入的一批页面中大多数都未被访问，则又是低效的。所以就需要釆用以预测为基础的预调页策略，将预计在不久之后便会被访问的页面预先调入内存。但目前预调页的成功率仅约50%。故这种策略主要用于进程的首次调入时，由程序员指出应该先调入哪些页。
  2. 请求调页策略。进程在运行中需要访问的页面不在内存而提出请求，由系统将所需页面调入内存。由这种策略调入的页一定会被访问，且这种策略比较易于实现，故在目前的虚拟存储器中大多釆用此策略。它的缺点在于每次只调入一页，调入调出页面数多时会花费过多的I/O开销。

##### 从何处调入页面
请求分页系统中的外存分为两部分：用于存放文件的文件区和用于存放对换页面的对换区。对换区通常是釆用连续分配方式，而文件区釆用离散分配方式，故对换区的磁盘I/O速度比文件区的更快。这样从何处调入页面有三种情况：

  1. 系统拥有足够的对换区空间：可以全部从对换区调入所需页面，以提髙调页速度。为此，在进程运行前，需将与该进程有关的文件从文件区复制到对换区。
  2. 系统缺少足够的对换区空间：凡不会被修改的文件都直接从文件区调入；而当换出这些页面时，由于它们未被修改而不必再将它们换出。但对于那些可能被修改的部分，在将它们换出时须调到对换区，以后需要时再从对换区调入。
  3. UNIX方式：与进程有关的文件都放在文件区，故未运行过的页面，都应从文件区调入。曾经运行过但又被换出的页面，由于是被放在对换区，因此下次调入时应从对换区调入。进程请求的共享页面若被其他进程调入内存，则无需再从对换区调入。

### 文件管理
#### 文件的概念和定义

1. 数据项
  数据项是文件系统中最低级的数据组织形式，可分为以下两种类型：
  
  - 基本数据项：用于描述一个对象的某种属性的一个值，如姓名、日期或证件号等，是数据中可命名的最小逻辑数据单位，即原子数据。
  - 组合数据项：由多个基本数据项组成。

2. 记录

  记录是一组相关的数据项的集合，用于描述一个对象在某方面的属性，如一个考生报名记录包括考生姓名、出生日期、报考学校代号、身份证号等一系列域。

3. 文件

  文件是指由创建者所定义的一组相关信息的集合，逻辑上可分为有结构文件和无结构文件两种。在有结构文件中，文件由一组相似记录组成，如报考某学校的所有考生的报考信息记录，又称记录式文件；而无结构文件则被看成是一个字符流，比如一个二进制文件或字符文件，又称流式文件。
  通常在操作系统中将程序和数据组织成文件。文件可以是数字、字母或二进制代码，基本访问单元可以是字节、 行或记录。文件可以长期存储于硬盘或其他二级存储器中,允许可控制的进程间共享访问，能够被组织成复杂的结构

#### 文件的属性、基本操作以及文件的打开和关闭
##### 文件的基本操作
  1. 创建文件：创建文件有两个必要步骤，一是在文件系统中为文件找到空间；二是在目录中为新文件创建条目，该条目记录文件名称、在文件系统中的位置及其他可能信息。
  2. 写文件：为了写文件，执行一个系统调用，指明文件名称和要写入文件的内容。对于给定文件名称，系统搜索目录以查找文件位置。系统必须为该文件维护一个写位置的指针。每当发生写操作，便更新写指针。
  3. 读文件：为了读文件，执行一个系统调用，指明文件名称和要读入文件块的内存位置。同样，需要搜索目录以找到相关目录项，系统维护一个读位置的指针。每当发生读操作时，更新读指针。一个进程通常只对一个文件读或写，所以当前操作位置可作为每个进程当前文件位置指针。由于读和写操作都使用同一指针，节省了空间也降低了系统复杂度。
  4. 文件重定位（文件寻址）：按某条件搜索目录，将当前文件位置设为给定值，并且不会读、写文件。
  5. 删除文件：先从目录中找到要删除文件的目录项，使之成为空项，然后回收该文件所占用的存储空间。
  6. 截断文件：允许文件所有属性不变，并删除文件内容，即将其长度设为0并释放其空间。

这6个基本操作可以组合执行其他文件操作。例如，一个文件的复制，可以创建新文件、 从旧文件读出并写入到新文件。
##### 文件的打开与关闭
因为许多文件操作都涉及为给定文件搜索相关目录条目，许多系统要求在首次使用文件时，使用系统调用open，将指明文件的属性（包括该文件在外存上的物理位置）从外存拷贝到内存打开文件目录表的一个表目中，并将该表目的编号（或称为索引）返回给用户。操作系统维护一个包含所有打开文件信息的表（打开文件表，open-file table）。当用户需要一个文件操作时，可通过该表的一个索引指定文件，就省略了搜索环节。当文件不再使用时，进程可以关闭它，操作系统从打开文件表中删除这一条目。
大部分操作系统要求在文件使用之前就被显式地打开。操作open会根据文件名搜索目录，并将目录条目复制到打开文件表。如果调用open的请求（创建、只读、读写、添加等）得到允许，进程就可以打开文件，而open通常返回一个指向打开文件表中的一个条目的指针。通过使用该指计（而非文件名）进行所有I/O操作，以简化步骤并节省资源。
整个系统表包含进程相关信息，如文件在磁盘的位置、访问日期和大小。一个进程打开一个文件，系统打开文件表就会为打开的文件增加相应的条目。当另一个进程执行open时，只不过是在其进程打开表中增加一个条目，并指向整个系统表的相应条目。通常，系统打开文件表的每个文件时，还用一个文件打开计数器(Open Count)，以记录多少进程打开了该文件。每个关闭操作close则使count递减，当打开计数器为0时，表示该文件不再被使用。系统将回收分配给该文件的内存空间等资源，若文件被修改过，则将文件写回外存，并将系统打开文件表中相应条目删除，最后释放文件的文件控制块(File Control Block, FCB)。
每个打开文件都有如下关联信息：
  
  1. 文件指针：系统跟踪上次读写位置作为当前文件位置指针，这种指针对打开文件的某个进程来说是唯一的，因此必须与磁盘文件属性分开保存。
  2. 文件打开计数：文件关闭时，操作系统必须重用其打开文件表条目，否则表内空间会不够用。因为多个进程可能打开同一个文件，所以系统在删除打开文件条目之前，必须等待最后一个进程关闭文件。该计数器跟踪打开和关闭的数量，当该计数为0 时，系统关闭文件，删除该条目。
  3. 文件磁盘位置：绝大多数文件操作都要求系统修改文件数据。该信息保存在内存中以免为每个操作都从磁盘中读取。
  4. 访问权限：每个进程打开文件都需要有一个访问模式（创建、只读、读写、添加等)。该信息保存在进程的打开文件表中以便操作系统能允许或拒绝之后的I/O请求。

#### 文件的逻辑结构：无结构文件(流式文件)和有结构文件(记录式文件)
文件的逻辑结构是从用户观点出发看到的文件的组织形式。文件的物理结构是从实现观点出发，又称为文件的存储结构，是指文件在外存上的存储组织形式。
##### 无结构文件（流式文件）
无结构文件是最简单的文件组织形式。无结构文件将数据按顺序组织成记录并积累保存，它是有序相关信息项的集合，以字节(Byte)为单位。由于无结构文件没有结构，因而对记录的访问只能通过穷举搜索的方式，故这种文件形式对大多数应用不适用。但字符流的无结构文件管理简单，用户可以方便地对其进行操作。所以，那些对基本信息单位操作不多的文件较适于釆用字符流的无结构方式，如源程序文件、目标代码文件等。
##### 有结构文件（记录式文件）
有结构文件按记录的组织形式可以分为：

1. 顺序文件。
  
  文件中的记录一个接一个地顺序排列，记录可以是定长的或变长的，可以顺序存储或以链表形式存储，在访问时需要顺序搜索文件。顺序文件有以下两种结构：

    - 第一种是串结构，记录之间的顺序与关键字无关。通常的办法是由时间决定，即按存入时间的先后排列，最先存入的记录作为第1个记录，其次存入的为第2个记录，依此类推。
    - 第二种是顺序结构，指文件中的所有记录按关键字顺序排列。
在对记录进行批量操作时，即每次要读或写一大批记录，对顺序文件的效率是所有逻辑文件中最高的；此外，也只有顺序文件才能存储在磁带上，并能有效地工作，但顺序文件对查找、修改、增加或删除单个记录的操作比较困难。

2.  索引文件

  变长记录文件只能顺序查找，系统开销较大。为此可以建立一张索引表以加快检索速度，索引表本身是定长记录的顺序文件。在记录很多或是访问要求高的文件中，需要引入索引以提供有效的访问。实际中，通过索引可以成百上千倍地提高访问速度。[如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F1155449139.jpg)

3. 索引顺序文件

  索引顺序文件将顺序文件中的所有记录分为若干个组，为顺序文件建立一张索引表，在索引表中为每组中的第一个记录建立一个索引项，其中含有该记录的关键字值和指向该记录的指针。
  [如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F1155P2G9.jpg)，主文件名包含姓名和其他数据项。姓名为关键字，索引表中为每组的第一个记录（不是每个记录）的关键字值，用指计指向主文件中该记录的起始位置。索引表只包含关键字和指计两个数据项，所有姓名关键字递增排列。主文件中记录分组排列，同一个组中关键字可以无序，但组与组之间关键字必须有序。查找一个记录时，通过索引表找到其所在的组，然后在该组中使用顺序查找就能很快地找到记录。
  如果记录数很多，可以釆用两级或多级索引。索引文件和索引顺序文件都提高了存取的速度，但因为配置索引表而增加了存储空间。

4. 直接文件或散列文件(Hash File)

  给定记录的键值或通过Hash函数转换的键值直接决定记录的物理地址。这种映射结构不同于顺序文件或索引文件，没有顺序的特性。散列文件有很高的存取速度，但是会引起冲突，即不同关键字的散列函数值相同。

#### 文件目录结构：单级、两级、多级(树形)和无环图目录结构
##### 文件控制块和索引结点
同进程管理一样，为实现目录管理，操作系统中引入了文件控制块的数据结构。

1. 文件控制块。
  
  文件控制块(FCB)是用来存放控制文件需要的各种信息的数据结构，以实现“按名存取”。FCB的有序集合称为文件目录，一个FCB就是一个文件目录项。为了创建一个新文件，系统将分配一个FCB并存放在文件目录中，成为目录项。
  FCB主要包含以下信息：
    
    1. 基本信息，如文件名、文件的物理位置、文件的逻辑结构、文件的物理结构等。
    2. 存取控制信息，如文件存取权限等。
    3. 使用信息，如文件建立时间、修改时间等。

2. 索引结点

  在检索目录文件的过程中，只用到了文件名，仅当找到一个目录项（查找文件名与目录项中文件名匹配）时，才需要从该目录项中读出该文件的物理地址。也就是说，在检索目录时，文件的其他描述信息不会用到，也不需调入内存。因此，有的系统（如UNIX）釆用了文件名和文件描述信息分开的方法，文件描述信息单独形成一个称为索引结点的数据结构，简称为 i 结点。在文件目录中的每个目录项仅由文件名和指向该文件所对应的i结点的指针构成。
  一个FCB的大小是64字节，盘块大小是1KB，则在每个盘块中可以存放16个FCB（注意，FCB必须连续存放）。而在UNIX系统中一个目录项仅占16字节，其中14字节是文件名，2字节是 i 结点指针。在1KB的盘块中可存放64个目录项。
  存放在磁盘上的索引结点称为磁盘索引结点，UNIX中的每个文件都有一个唯一的磁盘索引结点，主要包括以下几个方面：

    - 文件主标识符，拥有该文件的个人或小组的标识符。
    - 文件类型，包括普通文件、目录文件或特别文件。
    - 文件存取权限，各类用户对该文件的存取权限。
    - 文件物理地址，每个索引结点中含有13个地址项，即 iaddr(0) ~ iaddr(12)，它们以直接或间接方式给出数据文件所在盘块的编号。
    - 文件长度，以字节为单位。
    - 文件链接计数，在本文件系统中所有指向该文件的文件名的指针计数。
    - 文件存取时间，本文件最近被进程存取的时间、最近被修改的时间以及索引结点最‘ 近被修改的时间。
    - 文件被打开时，磁盘索引结点复制到内存的索引结点中，以便于使用。在内存索引结点中又增加了以下内容：
    - 索引结点编号，用于标识内存索引结点。
    - 状态，指示i结点是否上锁或被修改。
    - 访问计数，每当有一进程要访问此i结点时，计数加1，访问结束减1。
    - 逻辑设备号，文件所属文件系统的逻辑设备号。
    - 链接指针，设置分别指向空闲链表和散列队列的指针。

##### 目录结构
在理解一个文件系统的需求前，我们首先来考虑在目录这个层次上所需要执行的操作，这有助于后面文件系统的整体理解。

  1. 搜索：当用户使用一个文件时，需要搜索目录，以找到该文件的对应目录项。
  2. 创建文件：当创建一个新文件时，需要在目录中增加一个目录项。
  3. 删除文件：当删除一个文件时，需要在目录中删除相应的目录项。
  4. 显示目录：用户可以请求显示目录的内容，如显示该用户目录中的所有文件及属性。
  5. 修改目录：某些文件属性保存在目录中，因而这些属性的变化需要改变相应的目录项。

1. 单级目录结构。
  
  在整个文件系统中只建立一张目录表，每个文件占一个目录项，[如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F116245W96.jpg)，单级目录结构实现了 “按名存取”，但是存在查找速度慢、文件不允许重名、不便于文件共享等缺点，而且对于多用户的操作系统显然是不适用的。

2. 两级目录结构

  单级目录很容易造成文件名称的混淆，可以考虑釆用两级方案，将文件目录分成主文件目录(Master File Directory, MFD)和用户文件目录（User File Directory, UFD)两级，[如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F1162SXT.jpg)，两级目录结构可以解决多用户之间的文件重名问题，文件系统可以在目录上实现访问限制。但是两级目录结构缺乏灵活性，不能对文件分类。

3. 多级目录结构（树形目录结构)

  将两级目录结构的层次关系加以推广，就形成了多级目录结构，即树形目录结构，[如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F1163124E6.jpg)，树形目录结构可以很方便地对文件进行分类，层次结构清晰，也能够更有效地进行文件的管理和保护。但是，在树形目录中查找一个文件，需要按路径名逐级访问中间结点，这就增加了磁盘访问次数，无疑将影响查询速度。

4.  无环图目录结构

  树形目录结构可便于实现文件分类，但不便于实现文件共享，为此在树形目录结构的基础上增加了一些指向同一结点的有向边，使整个目录成为一个有向无环图。引入无环图目录结构是为了实现文件共享，[如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F11634005Q.jpg)，当某用户要求删除一个共享结点时，若系统只是简单地将它删除，当另一共享用户需要访问时，却无法找到这个文件而发生错误。为此可以为每个共享结点设置一个共享计数器，每当图中增加对该结点的共享链时，计数器加 1;每当某用户提出删除该结点时，计数器减1。仅当共享计数器为0时，才真正删除该结点，否则仅删除请求用户的共享链。无环图目录结构方便实现了文件的共享,但使得系统的管理变得更加复杂。

#### 共享文件：硬链接和软链接
两种链接方式都存在一个共同的问题，即每个共享文件都有几个文件名。换言之，每增加一条链接，就增加一个文件名。这实质上就是每个用户都使用自己的路径名去访问共享文件。当我们试图去遍历整个文件系统时，将会多次遍历到该共享文件。
硬链接和软链接都是文件系统中的静态共享方法，在文件系统中还存在着另外的共享需求，即两个进程同时对同一个文件进行操作，这样的共享可以称为动态共享。
##### 基于索引结点的共享方式（硬链接）
在这种共享方式中引用索引结点，即诸如文件的物理地址及其他的文件属性等信息，不再是放在目录项中，而是放在索引结点中。在文件目录中只设置文件名及指向相应索引结点的指针。在索引结点中还应有一个链接计数count,用于表示链接到本索引结点（亦即文件） 上的用户目录项的数目。当count=2时，表示有两个用户目录项链接到本文件上，或者说是有两个用户共享此文件。[如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F11H004348.jpg)
##### 利用符号链实现文件共享（软链接）
为使用户B能共享用户A的一个文件F,可以由系统创建一个LINK类型的新文件，也取名为F，并将文件F写入用户B的目录中，以实现用户B的目录与文件F的链接。在新文件中只包含被链接文件F的路径名。这样的链接方法被称为符号链接。新文件中的路径名则只被看做是符号链，当用户B要访问被链接的文件F且正要读 LINK类新文件时，操作系统根据新文件中的路径名去读该文件，从而实现了用户B对文件 F的共享。
在利用符号链方式实现文件共享时，只有文件的拥有者才拥有指向其索引结点的指针。而共享该文件的其他用户则只有该文件的路径名，并不拥有指向其索引结点的指针。这样，也就不会发生在文件主删除一共享文件后留下一悬空指针的情况。当文件的拥有者把一个共享文件删除后，其他用户通过符号链去访问它时，会出现访问失败，于是将符号链删除，此时不会产生任何影响。

#### 文件保护：文件访问类型和访问控制
为了防止文件共享可能会导致文件被破坏或未经核准的用户修改文件，文件系统必须控制用户对文件的存取，即解决对文件的读、写、执行的许可问题。为此，必须在文件系统中建立相应的文件保护机制。
口令和密码都是防止用户文件被他人存取或窃取，并没有控制用户对文件的访问类型。
##### 访问类型
对文件的保护可以从限制对文件的访问类型中出发。可加以控制的访问类型主要有以下几种：
  
  - 读：从文件中读。
  - 写：向文件中写。
  - 执行：将文件装入内存并执行。
  - 添加：将新信息添加到文件结尾部分。
  - 删除：删除文件，释放空间。
  - 列表清单：列出文件名和文件属性。

此外还可以对文件的重命名、复制、编辑等加以控制。这些高层的功能可以通过系统程序调用低层系统调用来实现。保护可以只在低层提供。
##### 访问控制
解决访问控制最常用的方法是根据用户身份进行控制。而实现基于身份访问的最为普通的方法是为每个文件和目录增加一个访问控制列表(Access-Control List, ACL)，以规定每个用户名及其所允许的访问类型。
精简的访问列表釆用拥有者、组和其他三种用户类型。

  - 拥有者：创建文件的用户。
  - 组：一组需要共享文件且具有类似访问的用户。
  - 其他：系统内的所有其他用户。

这样只需用三个域列出访问表中这三类用户的访问权限即可。文件拥有者在创建文件时，说明创建者用户名及所在的组名，系统在创建文件时也将文件主的名字、所属组名列在该文件的FCB中。用户访问该文件时，按照拥有者所拥有的权限访问文件，如果用户和拥有者在同一个用户组则按照同组权限访问，否则只能按其他用户权限访问。UNIX操作系统即釆用此种方法。
#### 文件系统层次结构
现代操作系统有多种文件系统类型（如FAT32、NTFS、 ext2、ext3、ext4等），因此文件系统的层次结构也不尽相同。[如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F11J145964.jpg)是一种合理的层次结构。

1. 用户调用接口
  
  文件系统为用户提供与文件及目录有关的调用，如新建、打开、读写、关闭、删除文件，建立、删除目录等。此层由若干程序模块组成，每一模块对应一条系统调用，用户发出系统调用时，控制即转入相应的模块。

2. 文件目录系统
  
  文件目录系统的主要功能是管理文件目录，其任务有管理活跃文件目录表、管理读写状态信息表、管理用户进程的打开文件表、管理与组织在存储设备上的文件目录结构、调用下一级存取控制模块。

3. 存取控制验证
  
  实现文件保护主要由该级软件完成，它把用户的访问要求与FCB中指示的访问控制权限进行比较，以确认访问的合法性。

4. 逻辑文件系统与文件信息缓冲区
  
  逻辑文件系统与文件信息缓冲区的主要功能是根据文件的逻辑结构将用户要读写的逻辑记录转换成文件逻辑结构内的相应块号。

5. 物理文件系统
  
  物理文件系统的主要功能是把逻辑记录所在的相对块号转换成实际的物理地址。

6. 分配模块
  
  分配模块的主要功能是管理辅存空间，即负责分配辅存空闲空间和回收辅存空间。

7. 设备管理程序模块
  
  设备管理程序模块的主要功能是分配设备、分配设备读写用缓冲区、磁盘调度、启动设备、处理设备中断、释放设备读写缓冲区、释放设备等。

#### 文件系统的实现：目录实现和文件实现
##### 目录实现
在读文件前，必须先打开文件。打开文件时，操作系统利用路径名找到相应目录项，目 录项中提供了查找文件磁盘块所需要的信息。目录实现的基本方法有线性列表和哈希表两种。

1. 线性列表

  最简单的目录实现方法是使用存储文件名和数据块指针的线性表。创建新文件时，必须 首先搜索目录表以确定没有同名的文件存在，然后在目录表后增加一个目录项。删除文件则 根据给定的文件名搜索目录表，接着释放分配给它的空间。若要重用目录项，有许多方法： 可以将目录项标记为不再使用，或者将它加到空闲目录项表上，还可以将目录表中最后一个 目录项复制到空闲位置，并降低目录表长度。釆用链表结构可以减少删除文件的时间。其优 点在于实现简单，不过由于线性表的特殊性，比较费时。

2. 哈希表

  哈希表根据文件名得到一个值，并返回一个指向线性列表中元素的指针。这种方法的优 点是查找非常迅速，插入和删除也较简单，不过需要一些预备措施来避免冲突。最大的困难 是哈希表长度固定以及哈希函数对表长的依赖性。

目录查询是通过在磁盘上反复搜索完成，需要不断地进行I/O操作，开销较大。所以如 前面所述，为了减少I/O操作，把当前使用的文件目录复制到内存，以后要使用该文件时只 要在内存中操作，从而降低了磁盘操作次数，提高了系统速度。

##### 文件实现

1. 文件分配方式

  文件分配对应于文件的物理结构，是指如何为文件分配磁盘块。常用的磁盘空间分配方 法有三种：连续分配、链接分配和索引分配。有的系统（如RD0S操作系统）对三种方法都支持，但是更普遍的是一个系统只提供一种方法的支持。

  1. 连续分配

  	连续分配方法要求每个文件在磁盘上占有一组连续的块，磁盘地址定义了磁盘上的一个线性排序。这种排序使作业访问磁盘时需要的寻道数和寻道时间最小。 一个文件的目录条目包括 开始块的地址和该文件所分配区域的长度。
  	连续分配支持顺序访问和直接访问。其优点是实现简单、存取速度快。缺点在于，文件 长度不宜动态增加，因为一个文件末尾后的盘块可能已经分配给其他文件，一旦需要增加， 就需要大量移动盘块。此外，反复增删文件后会产生外部碎片（与内存管理分配方式中的碎 片相似)，并且很难确定一个文件需要的空间大小，因而只适用于长度固定的文件。

  2. 链接分配

  	链接分配是釆取离散分配的方式，消除了外部碎片，故而显著地提高了 磁盘空间的利用率；又因为是根据文件的当前需求，为它分配必需的盘块，当文件动态增长 时，可以动态地再为它分配盘块，故而无需事先知道文件的大小。此外，对文件的增、删、 改也非常方便。链接分配又可以分为隐式链接和显式链接两种形式。

  	隐式连接[如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F11RUSK.jpg)所示。每个文件对应一个磁盘块的链表；磁盘块分布在磁盘的任何 地方，除最后一个盘块外，每一个盘块都有指向下一个盘块的指针，这些指针对用户是透明. 的。目录包括文件第一块的指针和最后一块的指针。
  	隐式链接分配的缺点在于无法直接访问盘块，只能通过指针顺序访问文件，以及盘块指 针消耗了一定的存储空间。隐式链接分配的稳定性也是一个问题，系统在运行过程中由于软 件或者硬件错误导致链表中的指针丢失或损坏，会导致文件数据的丢失。

  	显式链接，是指把用于链接文件各物理块的指针，显式地存放在内存的一张链接表中。 该表在整个磁盘仅设置一张，每个表项中存放链接指针，即下一个盘块号。在该表中，凡是 属于某一文件的第一个盘块号，或者说是每一条链的链首指针所对应的盘块号，均作为文件 地址被填入相应文件的FCB的“物理地址”字段中。由于查找记录的过程是在内存中进行 的，因而不仅显著地提高了检索速度，而且大大减少了访问磁盘的次数。由于分配给文件的 所有盘块号都放在该表中，故称该表为文件分配表（File Allocation Table, FAT)。
  	
  3. 索引分配

  	链接分配解决了连续分配的外部碎片和文件大小管理的问题。但是，链接分配不能有效支持直接访问（FAT除外）。索引分配解决了这个问题，它把每个文件的所 有的盘块号都集中放在一起构成索引块（表），[如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F11S33S57.jpg)
  	每个文件都有其索引块，这是一个磁盘块地址的数组。索引块的第i个条目指向文件的 第i个块。目录条目包括索引块的地址。要读第i块，通过索引块的第i个条目的指针来查 找和读入所需的块。
  	创建文件时，索引块的所有指针都设为空。当首次写入第i块时，先从空闲空间中取得 一个块，再将其地址写到索引块的第i个条目。索引分配支持直接访问，且没有外部碎片问 题。其缺点是由于索引块的分配，增加了系统存储空间的开销。索引块的大小是一个重要的 问题，每个文件必须有一个索引块，因此索引块应尽可能小，但索引块太小就无法支持大文 件。可以釆用以下机制来处理这个问题。
  	链接方案：一个索引块通常为一个磁盘块，因此，它本身能直接读写。为了处理大文件， 可以将多个索引块链接起来。
  	多层索引：多层索引使第一层索引块指向第二层的索引块，第二层索引块再指向文件块。 这种方法根据最大文件大小的要求，可以继续到第三层或第四层。
  	混合索引：将多种索引分配方式相结合的分配方式
  	此外，访问文件需要两次访问外存——首先要读取索引块的内容，然后再访问具体的磁 盘块，因而降低了文件的存取速度。为了解决这一问题，通常将文件的索引块读入内存的缓 冲区中，以加快文件的访问速度。

2. 文件存储空间管理

  1. 文件存储器空间的划分与初始化

  	一般来说，一个文件存储在一个文件卷中。文件 卷可以是物理盘的一部分，也可以是整个物理盘，支持超大型文件的文件卷也可以由多个物理盘组成，[如图](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F11S914336.jpg)
  	在一个文件卷中，文件数据信息的空间（文件区）和存放文件控制信息FCB的空间（目 录区）是分离的。由于存在很多种类的文件表示和存放格式，所以现代操作系统中一般都有 很多不同的文件管理模块，通过它们可以访问不同格式的逻辑卷中的文件。逻辑卷在提供文 件服务前，必须由对应的文件程序进行初始化，划分好目录区和文件区，建立空闲空间管理 表格及存放逻辑卷信息的超级块。

  2. 文件存储器空间管理

  	文件存储设备分成许多大小相同的物理块，并以块为单位交 换信息，因此，文件存储设备的管理实质上是对空闲块的组织和管理，它包括空闲块的组织、 分配与回收等问题。

  	1. 空闲表法

  		空闲表法属于连续分配方式，它与内存的动态分配方式类似，为每个文件分配一块连续的存储空间。系统为外存上的所有空闲区建立一张空闲盘块表，每个空闲区对应于一个空闲 表项，其中包括表项序号、该空闲区第一个盘块号、该区的空闲盘块数等信息。再将所有空闲区按其起始盘块号递增的次序排列。空闲盘区的分配与内存的动态分配类似，同样是釆 用首次适应算法、循环首次适应算法等。例如，在系统为某新创建的文件分配空闲盘块时，先顺序地检索空闲盘块表的各表项，直至找到第一个其大小能满足要求的 空闲区，再将该盘区分配给用户，同时修改空闲盘块表。系统在对用户所释放的存储空间进行回收时，也釆取类似于内存回收的方法，即要考虑回收区是否与空闲表中插入点的前区和后区相邻接，对相邻接者应予以合并。

  	2. 空闲链表法

  		将所有空闲盘区拉成一条空闲链，根据构成链所用的基本元素不同，可把链表分成两种形式：空闲盘块链和空闲盘区链。空闲盘块链是将磁盘上的所有空闲空间，以盘块为单位拉成一条链。空闲盘区链是将磁盘上的所有空闲盘区（每个盘区可包含若干个盘块）拉成一条链。在每个盘区上除含有用于指示下一个空闲盘区的指针外，还应有能指明本盘区大小（盘块数） 的信息。

  	3. 位示图法

  		位示图是利用二进制的一位来表示磁盘中一个盘块的使用情况，磁盘上所有的盘块都有一个二进制位与之对应。当其值为“0”时，表示对应的盘块空闲；当其值为“1”时，表示 对应的盘块已分配。
  		盘块的分配：

    		- 顺序扫描位示图，从中找出一个或一组其值为“0”的二进制位。
			- 将所找到的一个或一组二进制位，转换成与之对应的盘块号。假定找到的其值为“0”的二进制位，位于位示图的第i行、第j列，则其相应的盘块号应按下式计算（n代表每行的位数）：b = n (i-1) + j
			- 修改位示图，令map[i, j] = 1。

		盘块的回收：

			- 将回收盘块的盘块号转换成位示图中的行号和列号。转换公式为
    			i=(b-1)DIVn+1
    			j=(b-l)MOD n+1
			- 修改位示图，令map[i, j] = 0。

	4. 成组链接法

		空闲表法和空闲链表法都不适合用于大型文件系统，因为这会使空闲表或空闲链表太大。在UNIX系统中釆用的是成组链接法，这种方法结合了空闲表和空闲链表两种方法，克服了表太大的缺点。其大致的思想是:把顺序的n个空闲扇区地址保存在第一个空闲扇区内，其后一个空闲扇区内则保存另一顺序空闲扇区的地址，如此继续，直至所有空闲扇区均予以 链接。系统只需要保存一个指向第一个空闲扇区的指针。[如图](http://c.biancheng.net/cpp/uploads/allimg/140702/1-140F201422O21.jpg)
		表示文件存储器空闲空间的“位向量”表或第一个成组链块以及卷中的目录区、文件区划分信息都需要存放在辅存储器中，一般放在卷头位置，在UNIX系统中称为“超级块”。在对卷中文件进行操作前，“超级块”需要预先读入系统空间的主存，并且经常保持主存“超 级块”与辅存卷中“超级块”的一致性。

#### 磁盘的结构
磁盘(Disk)是由表面涂有磁性物质的金属或塑料构成的圆形盘片，通过一个称为磁头 的导体线圈从磁盘中存取数据。在读/
写操作期间，磁头固定，磁盘在下面高速旋转。[如图](http://c.biancheng.net/cpp/uploads/allimg/140702/1-140F2020643419.jpg)，磁盘的盘面上的数据存储在一组同心圆中，称为磁道。每个磁道与磁头一样宽,一个盘面有上千个磁道。磁道又划分为几百个扇区，每个扇区固定存储大小（通常为512B),一个扇区称为一个盘块。相邻磁道及相邻扇区间通过一定的间隙分隔开，以避免精度错误。多个盘片垂直堆叠，组成磁盘组，每个盘面对应一个磁头，所有磁头固定在一起，与磁盘中心的距离相同且一起移动。所有盘片上相对位置相同的磁道组成柱面。按照这种物理结构组织，扇区就是磁盘可寻址的最小存储单位，磁盘地址 用“柱面号 • 盘面号 • 扇区号（或块号）”表示。
磁盘按不同方式可以分为若干类型：磁头相对于盘片的径向方向固定的称为固定头磁盘，每个磁道一个磁头；磁头可移动的称为活动头磁盘，磁头臂可以来回伸缩定位磁道。磁盘永久固定在磁盘驱动器内的称为固定盘磁盘；可移动和替换的称为可换盘磁盘。
#### 磁盘调度算法
一次磁盘读写操作的时间由寻找（寻道）时间、延迟时间和传输时间决定，在磁盘存取时间的计算中，寻道时间与磁盘调度算法相关，而延迟时间和传输时间都与磁盘旋转速度相关，且为线性相关，所以在硬件上，转速是磁盘性能的一个非常重要的参数。
目前常用的磁盘调度算法有以下几种：

1. 先来先服务(First Come First Served, FCFS)算法

  FCFS算法根据进程请求访问磁盘的先后顺序进行调度，这是一种最简单的调度算法

2. 最短寻找时间优先(Shortest  Seek  Time  First, SSTF)算法

  SSTF算法选择调度处理的磁道是与当前磁头所在磁道距离最近的磁道，以使每次的寻找时间最短。当然，总是选择最小寻找时间并不能保证平均寻找时间最小，但是能提供比 FCFS算法更好的性能。这种算法会产生“饥饿”现象。

3. 扫描(SCAN)算法（又称电梯算法）

  SCAN算法在磁头当前移动方向上选择与当前磁头所在磁道距离最近的请求作为下一次服务的对象，由于磁头移动规律与电梯运行相似，故又称为电梯调度算法。SCAN算法对最近扫描过的区域不公平，因此，它在访问局部性方面不如FCFS算法和 SSTF算法好。

4. 循环扫描(Circulair SCAN, C-SCAN)算法

  在扫描算法的基础上规定磁头单向移动来提供服务，回返时直接快速移动至起始端而不服务任何请求。由于SCAN算法偏向于处理那些接近最里或最外的磁道的访问请求，所以使用改进型的C-SCAN算法来避免这个问题。釆用SCAN算法和C-SCAN算法时磁头总是严格地遵循从盘面的一端到另一端，显然，在实际使用时还可以改进，即磁头移动只需要到达最远端的一个请求即可返回，不需要到达磁盘端点。这种形式的SCAN算法和C-SCAN算法称为LOOK和C-LOOK调度。这是因为它们在朝一个给定方向移动前会查看是否有请求。注意，若无特别说明，也可以默认SCAN 算法和C-SCAN算法为LOOK和C-LOOK调度。

  FCFS算法太过简单，性能较差，仅在请求队列长度接近于1时才较为理想；SSTF算法较为通用和自然；SCAN算法和C-SCAN算法在磁盘负载较大时比较占优势。

  除减少寻找时间外，减少延迟时间也是提高磁盘传输效率的重要因素。可以对盘面扇区进行交替编号，对磁盘片组中的不同盘面错位命名。假设每个盘面有8个扇区，磁盘片组共 8个盘面，则可以釆用[如图](http://c.biancheng.net/cpp/uploads/allimg/140702/1-140F202542R36.jpg)的编号。

  磁盘是连续自转设备，磁头读/写一个物理块后，需要经过短暂的处理时间才能开始读/写下一块。假设逻辑记录数据连续存放在磁盘空间中，若在盘面上按扇区交替编号连续存放，则连续读/写多个记录时能减少磁头的延迟时间；同柱面不同盘面的扇区若能错位编号，连续读/写相邻两个盘面的逻辑记录时也能减少磁头延迟时间。

#### 磁盘的管理：磁盘初始化、引导块、坏块
##### 磁盘初始化
一个新的磁盘只是一个含有磁性记录材料的空白盘。在磁盘能存储数据之前，它必须分成扇区以便磁盘控制器能进行读和写操作，这个过程称为低级格式化（物理分区）。低级格式化为磁盘的每个扇区釆用特别的数据结构。每个扇区的数据结构通常由头、数据区域（通常为512B大小）和尾部组成。头部和尾部包含了一些磁盘控制器所使用的信息。

为了使用磁盘存储文件，操作系统还需要将自己的数据结构记录在磁盘上：第一步将磁盘分为由一个或多个柱面组成的分区（即我们熟悉的C盘、D盘等形式的分区）；第二步对物理分区进行逻辑格式化（创建文件系统)，操作系统将初始的文件系统数据结构存储到磁盘上，这些数据结构包括空闲和已分配的空间以及一个初始为空的目录。
##### 引导块
计算机启动时需要运行一个初始化程序（自举程序），它初始化CPU、寄存器、设备控制器和内存等，接着启动操作系统。为此，该自举程序应找到磁盘上的操作系统内核，装入内存，并转到起始地址，从而开始操作系统的运行。
自举程序通常保存在ROM中，为了避免改变自举代码需要改变ROM硬件的问题，故只在ROM中保留很小的自举装入程序，将完整功能的自举程序保存在磁盘的启动块上，启动块位于磁盘的固定位。拥有启动分区的磁盘称为启动磁盘或者系统磁盘。
##### 坏块
由于磁盘有移动部件且容错能力弱，所以容易导致一个或多个扇区损坏。部分磁盘甚至从出厂时就有坏扇区。根据所使用的磁盘和控制器，对这些块有多种处理方式。

对于简单磁盘，如电子集成驱动器（IDE)。坏扇区可手工处理，如MS-DOS的Format命令执行逻辑格式化时便会扫描磁盘以检查坏扇区。坏扇区在FAT表上会标明，因此程序不会使用。

对于复杂的磁盘，如小型计算机系统接口（SCSI)，其控制器维护一个磁盘坏块链表。该链表在出厂前进行低级格式化时就初始化了，并在磁盘的整个使用过程中不断更新。低级格式化将一些块保留作为备用，对操作系统透明。控制器可以用备用块来逻辑地替代坏块，这种方案称为扇区备用。

#### 文件系统知识点总结
##### 磁盘结构
引导控制块(Boot Control Block)包括系统从该分区引导操作系统所需要的信息。如果磁盘没有操作系统，那么这块的内容为空。它通常为分区的第一块。UFS称之为引导块(Boot Block)； NTFS 称之为分区引导扇区(Partition Boot Sector)。

分区控制块(Partition Control Block)包括分区详细信息，如分区的块数、块的大小、空闲块的数量和指计、空闲FCB的数量和指针等。UPS称之为超级块(Superblock)；而NTFS 称之为主控文件表(Master File Table)。
##### 内存结构
内存分区表包含所有安装分区的信息。
内存目录结构用来保存近来访问过的目录信息。对安装分区的目录，可以包括一个指向 分区表的指针。
系统范围的打开文件表，包括每个打开文件的FCB复制和其他信息。
单个进程的打开文件表，包括一个指向系统范围内已打开文件表中合适条目和其他信息 的指针。
##### 文件系统实现概述
为了创建一个文件，应用程序调用逻辑文件系统。逻辑文件系统知道目录结构形式，它将分配一个新的FCB给文件，把相应目录读入内存，用新的文件名更新该目录 和FCB,并将结果写回到磁盘。[如图](http://c.biancheng.net/cpp/uploads/allimg/140702/1-140F203220E27.png)显示了一个典型的FCB。
文件名不必是打开文件表的一部分，因为一旦完成对FCB在磁盘上的定位，系统就不再使用文件名了。对于访问打开文件表的索引，UNIX称之为文件描述符(File Descriptor)；而Windows 2000称之为文件句柄(File Handle)。因此，只要文件没有被关闭，所有文件操 作通过打开文件表来进行。
当一个进程关闭文件，就删除一个相应的单个进程打开文件表的条目即目录项，系统范围内打开文件表的打开数也会递减。当打开文件的所有用户都关闭了一个文件时，更新的文 件信息会复制到磁盘的目录结构中，系统范围的打开文件表的条目也将删除。
##### 混合索引分配的实现
混合索引分配已在UNIX系统中釆用。在UNK SystemV的索引结点中，共设置了13个地址项，即iaddr(0)~iaddr(12)。在BSD UNIX的索引结点中，共设置了13个地址项，它们都把所有的地址项分成两类，即直接地址和间接地址。

1. 直接地址

  为了提高对文件的检索速度，在索引结点中可设置10个直接地址项，即用iaddr(0)~iaddr(9)来存放直接地址。换言之，在这里的每项中所存放的是该文件数据所在盘块的盘块号。假如每个盘块的大小为4KB，当文件不大于40KB时，便可直接从索引结点中读出该文 件的全部盘块号。

2. 一次间接地址

  对于大、中型文件，只釆用直接地址并不现实。可再利用索引结点中的地址项iaddr(l0)来提供一次间接地址。这种方式的实质就是一级索引分配方式。图中的一次间址块也就是索引块，系统将分配给文件的多个盘块号记入其中。在一次间址块中可存放1024个盘块号， 因而允许文件长达4MB。

3. 多次间接地址

  当文件长度大于4MB+40KB（—次间址与10个直接地址项）时，系统还须釆用二次间 址分配方式。这时，用地址项iaddr(11)提供二次间接地址。该方式的实质是两级索引分配方式。系统此时是在二次间址块中记入所有一次间址块的盘号。在釆用二次间址方式时，文件最大长度可达4GB。同理，地址项iaddr(12)作为三次间接地址，其所允许的文件最大长度可达4TB。

### 操作系统输入/输出(I/O)管理
#### I/O设备及其分类
计算机系统中的I/O设备按使用特性可分为以下类型：

1. 人机交互类外部设备：用于同计算机用户之间交互的设备，如打印机、显示器、鼠标、键盘等。这类设备数据交换速度相对较慢，通常是以字节为单位进行数据交换。
2. 存储设备：用于存储程序和数据的设备，如磁盘、磁带、光盘等。这类设备用于数据交换，速度较快，通常以多字节组成的块为单位进行数据交换。
3. 网络通信设备：用于与远程设备通信的设备，如各种网络接口、调制解调器等。其速度介于前两类设备之间。网络通信设备在使用和管理上与前两类设备也有很大不同。

#### I/O(输入/输出)控制方式
设备管理的主要任务之一是控制设备和内存或处理机之间的数据传送，外围设备和内存之间的输入/输出控制方式有四种
##### 程序直接控制方式
[如图a](http://c.biancheng.net/cpp/uploads/allimg/140702/1-140F2151126349.jpg)，计算机从外部设备读取数据到存储器，每次读一个字的数据。对读入的每个字，CPU需要对外设状态进行循环检查，直到确定该字已经在I/O控制器的数据寄存器中。在程序直接控制方式中，由于CPU的高速性和I/O设备的低速性，致使CPU的绝大部分时间都处于等待I/O设备完成数据I/O的循环测试中，造成了CPU资源的极大浪费。在该方式中，CPU之所以要不断地测试I/O设备的状态，就是因为在CPU中没有釆用中断机构，使I/O设备无法向CPU报告它已完成了一个字符的输入操作。

程序直接控制方式虽然简单易于实现，但是其缺点也是显而易见的，由于cpu和I/O设备只能串行工作，导致CPU的利用率相当低。
##### 中断驱动方式
中断驱动方式的思想是，允许I/O设备主动打断CPU的运行并请求服务，从而“解放”CPU，使得其向I/O控制器发送读命令后可以继续做其他有用的工作。如图b。

从I/O控制器的角度来看，I/O控制器从CPU接收一个读命令，然后从外围设备读数据。一旦数据读入到该I/O控制器的数据寄存器，便通过控制线给CPU发出一个中断信号，表示数据已准备好，然后等待CPU请求该数据。I/O控制器收到CPU发出的取数据请求后，将数据放到数据总线上，传到CPU的寄存器中。至此，本次I/O操作完成，I/O控制器又可幵始下一次I/O操作。
从CPU的角度来看，CPU发出读命令，然后保存当前运行程序的上下文（现场，包括程序计数器及处理机寄存器），转去执行其他程序。在每个指令周期的末尾，CPU检查中断。当有来自I/O控制器的中断时，CPU保存当前正在运行程序的上下文，转去执行中断处理程序处理该中断。这时，CPU从I/O控制器读一个字的数据传送到寄存器，并存入主存。接着， CPU恢复发出I/O命令的程序（或其他程序）的上下文，然后继续运行。

中断驱动方式比程序直接控制方式有效，但由于数据中的每个字在存储器与I/O控制器之间的传输都必须经过CPU,这就导致了中断驱动方式仍然会消耗较多的CPU时间。
##### DMA方式
在中断驱动方式中，I/O设备与内存之间的数据交换必须要经过CPU中的寄存器，所以速度还是受限，而DMA（直接存储器存取）方式的基本思想是在I/O设备和内存之间开辟直接的数据交换通路，彻底“解放” CPU。DMA方式的特点是：

  1. 基本单位是数据块。
  2. 所传送的数据，是从设备直接送入内存的，或者相反。
  3. 仅在传送一个或多个数据块的开始和结束时，才需CPU干预，整块数据的传送是在 DMA控制器的控制下完成的。

为了实现在主机与控制器之间成块数据的直接交换，必须在DMA控制器中设置如下四类寄存器：

  - 命令/状态寄存器(CR)：用于接收从CPU发来的I/O命令或有关控制信息，或设备的状态。
  - 内存地址寄存器(MAR)：在输入时，它存放把数据从设备传送到内存的起始目标地址；在输出时，它存放由内存到设备的内存源地址。
  - 数据寄存器(DR)：用于暂存从设备到内存，或从内存到设备的数据。
  - 数据计数器(DC)：存放本次CPU要读或写的字（节）数。

DMA方式的工作过程是：CPU读写数据时，它给I/O控制器发出一条命令，启动DMA控制器，然后继续其他工作。之后CPU就把控制操作委托给DMA控制器，由该控制器负责处理。DMA控制器直接与存储器交互，传送整个数据块，每次传送一个字，这个过程不需要CPU参与。当传送完成后，DMA控制器发送一个中断信号给处理器。因此只有在传送开始和结束时才需要CPU的参与。

DMA控制方式与中断驱动方式的主要区别是中断驱动方式在每个数据需要传输时中断CPU，而DMA控制方式则是在所要求传送的一批数据全部传送结束时才中断CPU；此外，中断驱动方式数据传送是在中断处理时由CPU控制完成的，而DMA控制方式则是在DMA 控制器的控制下完成的。

##### 通道控制方式
I/O通道是指专门负责输入/输出的处理机。I/O通道方式是DMA方式的发展，它可以进一步减少CPU的干预，即把对一个数据块的读（或写）为单位的干预，减少为对一组数据块的读（或写）及有关的控制和管理为单位的干预。同时，又可以实现CPU、通道和I/O设备三者的并行操作，从而更有效地提高整个系统的资源利用率。

例如，当CPU要完成一组相关的读（或写）操作及有关控制时，只需向I/O通道发送一条I/O指令，以给出其所要执行的通道程序的首地址和要访问的I/O设备，通道接到该指令后，通过执行通道程序便可完成CPU指定的I/O任务，数据传送结束时向CPU发中断请求。I/O通道与一般处理机的区别是：通道指令的类型单一，没有自己的内存，通道所执行
的通道程序是放在主机的内存中的，也就是说通道与CPU共享内存。

I/O通道与DMA方式的区别是：DMA方式需要CPU来控制传输的数据块大小、传输的内存位置，而通道方式中这些信息是由通道控制的。另外，每个DMA控制器对应一台设备与内存传递数据，而一个通道可以控制多台设备与内存的数据交换。

#### I/O子系统的层次结构
在I/O软件中普遍釆用了层次式结构，将系统输入/输出功能组织成一系列的层次，每一层都利用其下层提供的服务，完成输入/输出功能中的某些子功能，并屏蔽这些功能实现的细节，向高层提供服务。在层次式结构的I/O软件中，只要层次间的接口不变，对某一层次中的软件的修改都不会引起其下层或高层代码的变更，仅最底层才涉及硬件的具体特性。[如图](http://c.biancheng.net/cpp/uploads/allimg/140702/1-140F215464T09.png)
设备控制器的主要功能为：

  - 接收和识别CPU或通道发来的命令，如磁盘控制器能接收读、写、查找等命令。
  - 实现数据交换，包括设备和控制器之间的数据传输；通过数据总线或通道，控制器和主存之间的数据传输。
  - 发现和记录设备及自身的状态信息，供CPU处理使用。
  - 设备地址识别。

为实现上述功能，设备控制器[如图](http://c.biancheng.net/cpp/uploads/allimg/140702/1-140F2154455533.jpg)，必须包含以下组成部分：

  - 设备控制器与CPU的接口。该接口有三类信号线：数据线、地址线和控制线。数据线通常与两类寄存器相连接：数据寄存器（存放从设备送来的输入数据或从CPU送来的输出数据）和控制/状态寄存器（存放从CPU送来的控制信息或设备的状态信息)。
  - 设备控制器与设备的接口。设备控制器连接设备需要相应数量的接口，一个接口连接一台设备。每个接口中都存在数据、控制和状态三种类型的信号。
  - I/O控制逻辑。用于实现对设备的控制。它通过一组控制线与CPU交互，对从CPU收到的I/O命令进行译码。CPU启动设备时，将启动命令发送给控制器，同时通过地:址线把地址发送给控制器，由控制器的I/O逻辑对地址进行译码，并相应地对所选设备进行控制。

#### I/O子系统概述和I/O调度的概念
##### I/O子系统概述
由于I/O设备种类繁多，功能和传输速率差异巨大，需要多种方法来进行设备控制。这些方法共同组成了操作系统内核的I/O子系统，它将内核的其他方面从繁重的I/O设备管理中解放出来。I/O核心子系统提供的服务主要有I/O调度、缓冲与高速缓存、设备分配与回收、假脱机、设备保护和差错处理等。
##### I/O调度概念
I/O调度就是确定-个好的顺序来执行这些I/O请求。应用程序所发布的系统调用的顺序不一定总是最佳选择，所以需要I/o调度来改善系统整体性能，使进程之间公平地共享设备访问，减少I/O完成所需要的平均等待时间。

操作系统开发人员通过为每个设备维护一个请求队列来实现调度。当一个应用程序执行阻塞I/O系统调用时，该请求就加到相应设备的队列上。I/O调度会重新安排队列顺序以改善系统总体效率和应用程序的平均响应时间。

I/O子系统还可以使用主存或磁盘上的存储空间的技术，如缓冲、高速缓冲、假脱机等，来改善计算机效率。
